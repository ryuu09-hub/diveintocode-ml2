{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint14\n",
    "## ディープラーニングフレームワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】公式Exampleを分担して実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFLowの公式Exampleのresearch（定番のモデルから最新のモデルまで多様なコードが公開されている）ディレクトリから\n",
    "\"adversarial_crypto\"を選択した。下記参考Git,文献である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[adversarial_crypto](https://github.com/tensorflow/models/tree/master/research/adversarial_crypto)\n",
    "\n",
    "[Learning to Protect Communications with Adversarial Neural Cryptography](https://arxiv.org/abs/1610.06918)\n",
    "\n",
    "[論文PDF](https://arxiv.org/pdf/1610.06918.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adversarial_crypto: 通信の自動暗号化\n",
    "\n",
    "通信保護とデータ・セキュリティに応用できるモデル\n",
    "特定の暗号アルゴリズムを規定しておらず、EndToEndの反復トレーニングにより、ニューラルネットワークがどのように暗号化と復号化を行うかを学習を実証\n",
    "\n",
    "ニューラルネットワークが秘密鍵を使用して他のニューラルネットワークから情報を保護することを学習できるかどうかを確認します。 (公開鍵を使って暗号化すると秘密鍵でのみ復号できます)\n",
    "具体的には、マルチエージェントシステムで機密性のプロパティを確保することに焦点を当て、それらのプロパティを敵の観点から指定します。 したがって、システムはアリスとボブという名前のニューラルネットワークで構成され、イブという名前の3番目のニューラルネットワークがアリスとボブ間の通信を盗聴することから学習するものを制限することを目指しています。\n",
    "これらのニューラルネットワークに特定の暗号アルゴリズムを処方することはありません。 \n",
    "代わりに、エンドツーエンドで敵対的にトレーニングします。 \n",
    "ニューラルネットワークは、暗号化と復号化の形式を実行する方法、および機密性の目標を満たすためにこれらの操作を選択的に適用する方法を学習できることを示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ニューラルネットワークと暗号化及び機密性の確保**\n",
    "（2016年10月２４日Google公表）\n",
    "\n",
    "**エンドツーエンドにおける三人のネットワーク構成**\n",
    "- アリス：メッセージ送信者。ボブに暗号化したメッセージを送りたい。\n",
    "- ボブ：メッセージ受信者。アリスから受け取った暗号文を復号したい。\n",
    "- イヴ：受動的な攻撃者（メッセージの改ざんはしない）。アリスからボブへの通信を傍受し、暗号文を復号したい。\n",
    "\n",
    "**通信手順**\n",
    "- アリスは平文Pを暗号文Cに暗号化しボブに送る。\n",
    "- ボブは暗号文Cを正確に複合し、複合文PBobを得たい。\n",
    "- イブも暗号文Cを傍受し複合文PEveを得たい。\n",
    "\n",
    "**登場人物をニューラルネットワークとして考える**\n",
    "ここで、アリス、ボブ、イブの各登場人物をニューラルネットワークAlice,Bob,Eveとする。\n",
    "- Aliceは平文Pとvを入力として受け取り暗号文Cを出力する\n",
    "- Bobは暗号文Cと秘密鍵Kを入力として受け取り複合文PBobを出力する\n",
    "- Eveは暗号文Cを入力として受け取り複合文PEveを出力する\n",
    "\n",
    "**point**\n",
    "暗号化の際に、特定の暗号アルゴリズムを指定して用いている訳ではない点。 \n",
    "既知のアルゴリズムを用いていないため、攻撃者もニューラルネットワークを構築して複合化を試みる。 \n",
    "また、攻撃者のニューラルネットワークEveは第三者的立場としての最善のモデルを使用することを仮定する。\n",
    "AliceとBobの間には、Eveには見えないワンタイムパッドを共有。このワンタイムパッドでは、送信ごとに浮動小数点の暗号キーが生成される。AliceとBob双方には、このワンタイムパッドを使って暗号化するよう指示したが、具体的な方法については指示をしていない。共有のワンタイムパッドを使ったXOR(排他的理論和)暗号化が一般的だが、そういった機能の実装については指示しなかった。\n",
    "\n",
    "\n",
    "**学習**\n",
    "- 全結合層を最初の層にもつ\n",
    "- 全結合層の後に畳み込み層のシーケンスが続き、最終的に平文または暗号文に適した サイズの出力を生成する\n",
    "\n",
    "BobとEveには、この暗号を解読するよう指示、Bobは共有のワンタイムパッド（鍵）にアクセスできるが、Aliceがどういった暗号化手段を使っているのか分からないため、学習していく必要がある。\n",
    "16bitのプレーンテキストを送信する際に、4,096個の例を用いて機械学習させていったところ、Bobは7,000回を超えた辺りからbitの誤りが急激に低下し、15,000回以降、0に近い値で推移したのに対し、Eveは最良時でも約5bit、平均して7～8bitの誤りがあったという。（半角文字１byte=8bit）\n",
    "\n",
    "つまり、Bobは共有のワンタイムパッドから暗号化アルゴリズムを見出し、Aliceから送られた暗号をほぼ解読できたが、ワンタイムパッドが共有されていないEveでは内容を推測することしかできず、解読できなかったわけだ。\n",
    "Googleは、こうした研究結果は、ニューラルネットワークは自身の通信を暗号化するだけでなく、外部攻撃からの保護にも活用できるとしている。\n",
    "\n",
    "現代のRSA暗号やSSL暗号は、コンピュータの速度の制限によって強度を担保している暗号システムであるため、計算速度が猛烈に早い量子コンピュータが本格的に実用化した場合、秒で解読できる。\n",
    "ニューラル暗号は、コンピュータの計算速度に依存せず、復号化キーなければわからない。 　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コードの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1210 08:00:49.834367 4552873408 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Batch size:  4096\n",
      "#       Iter\t     Bob_Recon_Error\t     Eve_Recon_Error\n",
      "         0\t                8.01\t                7.98\n",
      "       200\t                7.79\t                7.38\n",
      "       400\t                6.07\t                6.22\n",
      "       600\t                4.29\t                5.89\n",
      "       800\t                2.26\t                5.84\n",
      "      1000\t                1.44\t                6.07\n",
      "      1200\t                1.00\t                6.27\n",
      "      1400\t                0.73\t                6.46\n",
      "      1600\t                0.57\t                6.52\n",
      "      1800\t                0.46\t                6.72\n",
      "      2000\t                0.38\t                6.77\n",
      "      2200\t                0.32\t                6.86\n",
      "      2400\t                0.27\t                6.97\n",
      "      2600\t                0.23\t                7.03\n",
      "      2800\t                0.19\t                7.07\n",
      "      3000\t                0.17\t                7.11\n",
      "      3200\t                0.15\t                7.15\n",
      "      3400\t                0.13\t                7.24\n",
      "      3600\t                0.12\t                7.21\n",
      "      3800\t                0.11\t                7.24\n",
      "      4000\t                0.10\t                7.28\n",
      "      4200\t                0.09\t                7.34\n",
      "      4400\t                0.08\t                7.32\n",
      "      4600\t                0.07\t                7.38\n",
      "      4800\t                0.07\t                7.34\n",
      "      5000\t                0.06\t                7.39\n",
      "      5200\t                0.05\t                7.44\n",
      "      5400\t                0.05\t                7.38\n",
      "      5600\t                0.04\t                7.41\n",
      "      5800\t                0.04\t                7.42\n",
      "      6000\t                0.04\t                7.47\n",
      "      6200\t                0.04\t                7.41\n",
      "      6400\t                0.03\t                7.42\n",
      "      6600\t                0.03\t                7.51\n",
      "      6800\t                0.03\t                7.42\n",
      "      7000\t                0.03\t                7.39\n",
      "      7200\t                0.03\t                7.47\n",
      "      7400\t                0.03\t                7.45\n",
      "      7600\t                0.02\t                7.42\n",
      "      7800\t                0.02\t                7.46\n",
      "      8000\t                0.02\t                7.50\n",
      "      8200\t                0.02\t                7.42\n",
      "      8400\t                0.02\t                7.48\n",
      "      8600\t                0.02\t                7.44\n",
      "      8800\t                0.02\t                7.45\n",
      "      9000\t                0.02\t                7.43\n",
      "      9200\t                0.01\t                7.45\n",
      "      9400\t                0.01\t                7.52\n",
      "      9600\t                0.01\t                7.50\n",
      "      9800\t                0.01\t                7.47\n",
      "     10000\t                0.02\t                7.39\n",
      "     10200\t                0.01\t                7.49\n",
      "     10400\t                0.01\t                7.50\n",
      "     10600\t                0.01\t                7.47\n",
      "     10800\t                0.01\t                7.53\n",
      "     11000\t                0.01\t                7.52\n",
      "     11200\t                0.01\t                7.51\n",
      "     11400\t                0.01\t                7.61\n",
      "     11600\t                0.01\t                7.56\n",
      "     11800\t                0.01\t                7.55\n",
      "     12000\t                0.01\t                7.56\n",
      "     12200\t                0.01\t                7.55\n",
      "     12400\t                0.01\t                7.52\n",
      "     12600\t                0.01\t                7.56\n",
      "     12800\t                0.01\t                7.51\n",
      "     13000\t                0.01\t                7.47\n",
      "     13200\t                0.01\t                7.48\n",
      "     13400\t                0.01\t                7.41\n",
      "     13600\t                0.01\t                7.48\n",
      "     13800\t                0.01\t                7.41\n",
      "     14000\t                0.01\t                7.51\n",
      "     14200\t                0.01\t                7.51\n",
      "     14400\t                0.01\t                7.49\n",
      "     14600\t                0.01\t                7.54\n",
      "     14800\t                0.00\t                7.54\n",
      "     15000\t                0.00\t                7.50\n",
      "     15200\t                0.00\t                7.56\n",
      "     15400\t                0.01\t                7.50\n",
      "     15600\t                0.01\t                7.51\n",
      "     15800\t                0.01\t                7.45\n",
      "     16000\t                0.01\t                7.51\n",
      "     16200\t                0.01\t                7.44\n",
      "     16400\t                0.01\t                7.45\n",
      "     16600\t                0.01\t                7.49\n",
      "     16800\t                0.01\t                7.46\n",
      "     17000\t                0.01\t                7.45\n",
      "     17200\t                0.01\t                7.48\n",
      "     17400\t                0.01\t                7.50\n",
      "     17600\t                0.00\t                7.57\n",
      "     17800\t                0.01\t                7.50\n",
      "     18000\t                0.01\t                7.38\n",
      "     18200\t                0.01\t                7.39\n",
      "     18400\t                0.01\t                7.33\n",
      "     18600\t                0.01\t                7.37\n",
      "     18800\t                0.01\t                7.33\n",
      "     19000\t                0.02\t                7.21\n",
      "     19200\t                0.01\t                7.41\n",
      "     19400\t                0.01\t                7.47\n",
      "     19600\t                0.01\t                7.52\n",
      "     19800\t                0.01\t                7.48\n",
      "     20000\t                0.01\t                7.38\n",
      "     20200\t                0.01\t                7.33\n",
      "     20400\t                0.01\t                7.32\n",
      "     20600\t                0.02\t                7.15\n",
      "     20800\t                0.02\t                7.19\n",
      "     21000\t                0.02\t                7.19\n",
      "     21200\t                0.02\t                7.18\n",
      "     21400\t                0.02\t                7.11\n",
      "     21600\t                0.02\t                7.09\n",
      "     21800\t                0.03\t                7.12\n",
      "     22000\t                0.02\t                7.21\n",
      "     22200\t                0.02\t                7.23\n",
      "     22400\t                0.02\t                7.26\n",
      "     22600\t                0.01\t                7.47\n",
      "     22800\t                0.01\t                7.35\n",
      "     23000\t                0.02\t                7.40\n",
      "     23200\t                0.01\t                7.34\n",
      "     23400\t                0.01\t                7.43\n",
      "     23600\t                0.01\t                7.57\n",
      "     23800\t                0.01\t                7.60\n",
      "     24000\t                0.01\t                7.63\n",
      "     24200\t                0.01\t                7.52\n",
      "     24400\t                0.01\t                7.61\n",
      "     24600\t                0.01\t                7.57\n",
      "     24800\t                0.01\t                7.53\n",
      "     25000\t                0.01\t                7.58\n",
      "     25200\t                0.01\t                7.52\n",
      "     25400\t                0.00\t                7.57\n",
      "     25600\t                0.01\t                7.57\n",
      "     25800\t                0.01\t                7.60\n",
      "     26000\t                0.01\t                7.52\n",
      "     26200\t                0.00\t                7.52\n",
      "     26400\t                0.01\t                7.57\n",
      "     26600\t                0.01\t                7.46\n",
      "     26800\t                0.01\t                7.54\n",
      "     27000\t                0.01\t                7.52\n",
      "     27200\t                0.01\t                7.56\n",
      "     27400\t                0.01\t                7.57\n",
      "     27600\t                0.01\t                7.57\n",
      "     27800\t                0.01\t                7.53\n",
      "     28000\t                0.01\t                7.51\n",
      "     28200\t                0.01\t                7.56\n",
      "     28400\t                0.01\t                7.58\n",
      "     28600\t                0.01\t                7.50\n",
      "     28800\t                0.01\t                7.53\n",
      "     29000\t                0.01\t                7.57\n",
      "     29200\t                0.01\t                7.59\n",
      "     29400\t                0.01\t                7.58\n",
      "     29600\t                0.01\t                7.56\n",
      "     29800\t                0.00\t                7.56\n",
      "     30000\t                0.01\t                7.56\n",
      "     30200\t                0.01\t                7.50\n",
      "     30400\t                0.01\t                7.56\n",
      "     30600\t                0.01\t                7.53\n",
      "     30800\t                0.01\t                7.51\n",
      "     31000\t                0.01\t                7.44\n",
      "     31200\t                0.00\t                7.61\n",
      "     31400\t                0.01\t                7.58\n",
      "     31600\t                0.01\t                7.61\n",
      "     31800\t                0.01\t                7.53\n",
      "     32000\t                0.01\t                7.49\n",
      "     32200\t                0.01\t                7.52\n",
      "     32400\t                0.00\t                7.56\n",
      "     32600\t                0.01\t                7.51\n",
      "     32800\t                0.01\t                7.53\n",
      "     33000\t                0.01\t                7.58\n",
      "     33200\t                0.01\t                7.58\n",
      "     33400\t                0.00\t                7.53\n",
      "     33600\t                0.01\t                7.51\n",
      "     33800\t                0.01\t                7.38\n",
      "     34000\t                0.01\t                7.45\n",
      "     34200\t                0.01\t                7.52\n",
      "     34400\t                0.01\t                7.57\n",
      "     34600\t                0.01\t                7.53\n",
      "     34800\t                0.00\t                7.50\n",
      "     35000\t                0.00\t                7.58\n",
      "     35200\t                0.01\t                7.52\n",
      "     35400\t                0.00\t                7.54\n",
      "     35600\t                0.01\t                7.53\n",
      "     35800\t                0.01\t                7.52\n",
      "     36000\t                0.01\t                7.57\n",
      "     36200\t                0.01\t                7.55\n",
      "     36400\t                0.00\t                7.58\n",
      "     36600\t                0.00\t                7.58\n",
      "     36800\t                0.01\t                7.58\n",
      "     37000\t                0.00\t                7.57\n",
      "     37200\t                0.00\t                7.60\n",
      "     37400\t                0.00\t                7.59\n",
      "     37600\t                0.00\t                7.63\n",
      "     37800\t                0.00\t                7.63\n",
      "     38000\t                0.00\t                7.29\n",
      "     38200\t                0.01\t                7.54\n",
      "     38400\t                0.01\t                7.56\n",
      "     38600\t                0.01\t                7.60\n",
      "     38800\t                0.00\t                7.60\n",
      "     39000\t                0.00\t                7.53\n",
      "     39200\t                0.01\t                7.62\n",
      "     39400\t                0.00\t                7.52\n",
      "     39600\t                0.00\t                7.57\n",
      "     39800\t                0.01\t                7.51\n",
      "     40000\t                0.00\t                7.45\n",
      "     40200\t                0.01\t                7.54\n",
      "     40400\t                0.01\t                7.53\n",
      "     40600\t                0.01\t                7.57\n",
      "     40800\t                0.00\t                7.56\n",
      "     41000\t                0.00\t                7.55\n",
      "     41200\t                0.00\t                7.62\n",
      "     41400\t                0.00\t                7.59\n",
      "     41600\t                0.01\t                6.67\n",
      "     41800\t                0.00\t                7.52\n",
      "     42000\t                0.00\t                7.59\n",
      "     42200\t                0.00\t                7.60\n",
      "     42400\t                0.00\t                7.59\n",
      "     42600\t                0.01\t                7.54\n",
      "     42800\t                0.01\t                7.57\n",
      "     43000\t                0.01\t                7.57\n",
      "     43200\t                0.01\t                7.56\n",
      "     43400\t                0.01\t                7.57\n",
      "     43600\t                0.01\t                7.63\n",
      "     43800\t                0.00\t                7.60\n",
      "     44000\t                0.01\t                7.56\n",
      "     44200\t                0.00\t                7.61\n",
      "     44400\t                0.01\t                7.53\n",
      "     44600\t                0.00\t                7.56\n",
      "     44800\t                0.01\t                7.55\n",
      "     45000\t                0.00\t                7.60\n",
      "     45200\t                0.01\t                7.50\n",
      "     45400\t                0.01\t                7.46\n",
      "     45600\t                0.00\t                7.57\n",
      "     45800\t                0.01\t                7.53\n",
      "     46000\t                0.00\t                7.60\n",
      "     46200\t                0.00\t                7.54\n",
      "     46400\t                0.00\t                7.58\n",
      "     46600\t                0.00\t                7.58\n",
      "     46800\t                0.01\t                7.60\n",
      "     47000\t                0.00\t                7.57\n",
      "     47200\t                0.01\t                7.62\n",
      "     47400\t                0.01\t                7.61\n",
      "     47600\t                0.01\t                7.63\n",
      "     47800\t                0.00\t                7.59\n",
      "     48000\t                0.00\t                7.70\n",
      "Target losses achieved.\n",
      "Loss after eve extra training:\n",
      "         0\t                0.00\t                7.53\n",
      "Resetting Eve\n",
      "     10000\t                0.00\t                7.21\n",
      "     20000\t                0.00\t                6.57\n",
      "     30000\t                0.00\t                6.55\n",
      "     40000\t                0.00\t                6.56\n",
      "     50000\t                0.00\t                6.62\n",
      "     60000\t                0.00\t                6.58\n",
      "     70000\t                0.00\t                6.56\n",
      "     80000\t                0.00\t                6.53\n",
      "     90000\t                0.00\t                6.55\n",
      "    100000\t                0.00\t                6.55\n",
      "    110000\t                0.00\t                6.56\n",
      "    120000\t                0.00\t                6.55\n",
      "    130000\t                0.00\t                6.53\n",
      "    140000\t                0.00\t                6.58\n",
      "    150000\t                0.00\t                6.53\n",
      "    160000\t                0.00\t                6.53\n",
      "    170000\t                0.00\t                6.55\n",
      "    180000\t                0.00\t                6.55\n",
      "    190000\t                0.00\t                6.55\n",
      "    200000\t                0.00\t                6.51\n",
      "    210000\t                0.00\t                6.53\n",
      "    220000\t                0.00\t                6.51\n",
      "    230000\t                0.00\t                6.57\n",
      "    240000\t                0.00\t                6.49\n",
      "    250000\t                0.00\t                6.54\n",
      "    250000\t                0.00\t                6.54\n",
      "Resetting Eve\n",
      "     10000\t                0.00\t                7.52\n",
      "     20000\t                0.00\t                6.67\n",
      "     30000\t                0.00\t                6.62\n",
      "     40000\t                0.00\t                6.66\n",
      "     50000\t                0.00\t                6.64\n",
      "     60000\t                0.00\t                6.66\n",
      "     70000\t                0.00\t                6.65\n",
      "     80000\t                0.00\t                6.63\n",
      "     90000\t                0.00\t                6.65\n",
      "    100000\t                0.00\t                6.64\n",
      "    110000\t                0.00\t                6.64\n",
      "    120000\t                0.00\t                6.59\n",
      "    130000\t                0.00\t                6.65\n",
      "    140000\t                0.00\t                6.65\n",
      "    150000\t                0.00\t                6.63\n",
      "    160000\t                0.00\t                6.70\n",
      "    170000\t                0.00\t                6.63\n",
      "    180000\t                0.00\t                6.66\n",
      "    190000\t                0.00\t                6.65\n",
      "    200000\t                0.00\t                6.66\n",
      "    210000\t                0.00\t                6.63\n",
      "    220000\t                0.00\t                6.58\n",
      "    230000\t                0.00\t                6.61\n",
      "    240000\t                0.00\t                6.61\n",
      "    250000\t                0.00\t                6.66\n",
      "    250000\t                0.00\t                6.63\n",
      "Resetting Eve\n",
      "     10000\t                0.00\t                7.42\n",
      "     20000\t                0.00\t                6.62\n",
      "     30000\t                0.00\t                6.59\n",
      "     40000\t                0.00\t                6.56\n",
      "     50000\t                0.00\t                6.58\n",
      "     60000\t                0.00\t                6.58\n",
      "     70000\t                0.00\t                6.59\n",
      "     80000\t                0.00\t                6.59\n",
      "     90000\t                0.00\t                6.61\n",
      "    100000\t                0.00\t                6.64\n",
      "    110000\t                0.00\t                6.55\n",
      "    120000\t                0.00\t                6.63\n",
      "    130000\t                0.00\t                6.57\n",
      "    140000\t                0.00\t                6.57\n",
      "    150000\t                0.00\t                6.54\n",
      "    160000\t                0.00\t                6.60\n",
      "    170000\t                0.00\t                6.58\n",
      "    180000\t                0.00\t                6.58\n",
      "    190000\t                0.00\t                6.63\n",
      "    200000\t                0.00\t                6.59\n",
      "    210000\t                0.00\t                6.57\n",
      "    220000\t                0.00\t                6.61\n",
      "    230000\t                0.00\t                6.55\n",
      "    240000\t                0.00\t                6.55\n",
      "    250000\t                0.00\t                6.57\n",
      "    250000\t                0.00\t                6.57\n",
      "Resetting Eve\n",
      "     10000\t                0.00\t                7.54\n",
      "     20000\t                0.00\t                6.74\n",
      "     30000\t                0.00\t                6.64\n",
      "     40000\t                0.00\t                6.63\n",
      "     50000\t                0.00\t                6.62\n",
      "     60000\t                0.00\t                6.63\n",
      "     70000\t                0.00\t                6.66\n",
      "     80000\t                0.00\t                6.64\n",
      "     90000\t                0.00\t                6.65\n",
      "    100000\t                0.00\t                6.61\n",
      "    110000\t                0.00\t                6.60\n",
      "    120000\t                0.00\t                6.58\n",
      "    130000\t                0.00\t                6.59\n",
      "    140000\t                0.00\t                6.65\n",
      "    150000\t                0.00\t                6.69\n",
      "    160000\t                0.00\t                6.65\n",
      "    170000\t                0.00\t                6.67\n",
      "    180000\t                0.00\t                6.66\n",
      "    190000\t                0.00\t                6.65\n",
      "    200000\t                0.00\t                6.70\n",
      "    210000\t                0.00\t                6.62\n",
      "    220000\t                0.00\t                6.65\n",
      "    230000\t                0.00\t                6.64\n",
      "    240000\t                0.00\t                6.67\n",
      "    250000\t                0.00\t                6.67\n",
      "    250000\t                0.00\t                6.67\n",
      "Resetting Eve\n",
      "     10000\t                0.00\t                7.67\n",
      "     20000\t                0.00\t                6.70\n",
      "     30000\t                0.00\t                6.66\n",
      "     40000\t                0.00\t                6.64\n",
      "     50000\t                0.00\t                6.64\n",
      "     60000\t                0.00\t                6.73\n",
      "     70000\t                0.00\t                6.63\n",
      "     80000\t                0.00\t                6.63\n",
      "     90000\t                0.00\t                6.64\n",
      "    100000\t                0.00\t                6.59\n",
      "    110000\t                0.00\t                6.67\n",
      "    120000\t                0.00\t                6.63\n",
      "    130000\t                0.00\t                6.65\n",
      "    140000\t                0.00\t                6.64\n",
      "    150000\t                0.00\t                6.66\n",
      "    160000\t                0.00\t                6.58\n",
      "    170000\t                0.00\t                6.64\n",
      "    180000\t                0.00\t                6.64\n",
      "    190000\t                0.00\t                6.61\n",
      "    200000\t                0.00\t                6.69\n",
      "    210000\t                0.00\t                6.67\n",
      "    220000\t                0.00\t                6.64\n",
      "    230000\t                0.00\t                6.64\n",
      "    240000\t                0.00\t                6.71\n",
      "    250000\t                0.00\t                6.61\n",
      "    250000\t                0.00\t                6.68\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Adversarial training to learn trivial encryption functions,\n",
    "from the paper \"Learning to Protect Communications with\n",
    "Adversarial Neural Cryptography\", Abadi & Andersen, 2016.\n",
    "https://arxiv.org/abs/1610.06918\n",
    "This program creates and trains three neural networks,\n",
    "termed Alice, Bob, and Eve.  Alice takes inputs\n",
    "in_m (message), in_k (key) and outputs 'ciphertext'.\n",
    "Bob takes inputs in_k, ciphertext and tries to reconstruct\n",
    "the message.\n",
    "Eve is an adversarial network that takes input ciphertext\n",
    "and also tries to reconstruct the message.\n",
    "The main function attempts to train these networks and then\n",
    "evaluates them, all on random plaintext and key values.\n",
    "\"\"\"\n",
    "\n",
    "# TensorFlow Python 3 compatibility\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import signal\n",
    "import sys\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "# 定義用のflagを作成,tf.app.flags.FLAGSを使うと、TensorFlowのPythonファイルを実行する際にパラメタを付与できる\n",
    "flags = tf.app.flags \n",
    "\n",
    "# floatの定義\n",
    "flags.DEFINE_float('learning_rate', 0.0008, 'Constant learning rate')\n",
    "# intの定義\n",
    "flags.DEFINE_integer('batch_size', 4096, 'Batch size')\n",
    "\n",
    "# 参照用のflagを作成\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Input and output configuration.\n",
    "TEXT_SIZE = 16\n",
    "KEY_SIZE = 16\n",
    "\n",
    "# Training parameters.\n",
    "ITERS_PER_ACTOR = 1\n",
    "EVE_MULTIPLIER = 2  # Train Eve 2x for every step of Alice/Bob\n",
    "\n",
    "# Train until either max loops or Alice/Bob \"good enough\":\n",
    "# Alice/Bobが十分になるまで学習を繰り返す\n",
    "MAX_TRAINING_LOOPS = 850000\n",
    "BOB_LOSS_THRESH = 0.02  # Exit when Bob loss < 0.02 and Eve > 7.7 bits\n",
    "EVE_LOSS_THRESH = 7.7\n",
    "\n",
    "# Logging and evaluation.\n",
    "PRINT_EVERY = 200  # In training, log every 200 steps.　トレーニングでは２００ステップごとに記録\n",
    "EVE_EXTRA_ROUNDS = 2000  # At end, train eve a bit more.　最後に、イブをもう少し訓練\n",
    "RETRAIN_EVE_ITERS = 10000  # Retrain eve up to ITERS*LOOPS times.　ITERS * LOOPS回までイブを再トレーニングし\n",
    "RETRAIN_EVE_LOOPS = 25  # With an evaluation each loop　ループごとに評価\n",
    "NUMBER_OF_EVE_RESETS = 5  # And do this up to 5 times with a fresh eve.　洗練されたEveで５回回す\n",
    "# Use EVAL_BATCHES samples each time we check accuracy.　EVAL_BATCHESを使いaccuracy確認\n",
    "EVAL_BATCHES = 1\n",
    "\n",
    "\n",
    "def batch_of_random_bools(batch_size, n):\n",
    "  \"\"\"Return a batch of random \"boolean\" numbers.\n",
    "  Args:\n",
    "    batch_size:  Batch size dimension of returned tensor.\n",
    "    n:  number of entries per batch.\n",
    "  Returns:\n",
    "    A [batch_size, n] tensor of \"boolean\" numbers, where each number is\n",
    "    preresented as -1 or 1.\n",
    "  \"\"\"\n",
    "\n",
    "  as_int = tf.random.uniform([batch_size, n], minval=0, maxval=2, dtype=tf.int32)\n",
    "    expanded_range = (as_int * 2) - 1\n",
    "    \n",
    "    return tf.cast(expanded_range, tf.float32) #tf.cast()でint型→float型へ変換。\n",
    "\n",
    "\n",
    "class AdversarialCrypto(object):\n",
    "  \"\"\"Primary model implementation class for Adversarial Neural Crypto.\n",
    "  This class contains the code for the model itself,\n",
    "  and when created, plumbs the pathways from Alice to Bob and\n",
    "  Eve, creates the optimizers and loss functions, etc.\n",
    "  Attributes:\n",
    "    eve_loss:  Eve's loss function.\n",
    "    bob_loss:  Bob's loss function.  Different units from eve_loss.\n",
    "    eve_optimizer:  A tf op that runs Eve's optimizer.\n",
    "    bob_optimizer:  A tf op that runs Bob's optimizer.\n",
    "    bob_reconstruction_loss:  Bob's message reconstruction loss,\n",
    "      which is comparable to eve_loss.\n",
    "    reset_eve_vars:  Execute this op to completely reset Eve.\n",
    "    \n",
    "    モデルの本体コードが含まれるクラス、実行されるとアリスからボブとイブへ経路が組込まれ、ロスやオプティマイザーが生成される。\n",
    "  \"\"\"\n",
    "\n",
    "  def get_message_and_key(self):\n",
    "    \"\"\"Generate random pseudo-boolean key and message values.\"\"\"\n",
    "    #キーとメッセージ値生成\n",
    "\n",
    "    batch_size = tf.compat.v1.placeholder_with_default(FLAGS.batch_size, shape=[])\n",
    "\n",
    "    in_m = batch_of_random_bools(batch_size, TEXT_SIZE)\n",
    "    in_k = batch_of_random_bools(batch_size, KEY_SIZE)\n",
    "    return in_m, in_k\n",
    "\n",
    "  def model(self, collection, message, key=None):\n",
    "    \"\"\"The model for Alice, Bob, and Eve.  If key=None, the first fully connected layer\n",
    "    takes only the message as inputs.  Otherwise, it uses both the key\n",
    "    and the message.\n",
    "    Args:\n",
    "      collection:  The graph keys collection to add new vars to.\n",
    "      message:  The input message to process.\n",
    "      key:  The input key (if any) to use.\n",
    "    \"\"\"\n",
    "\n",
    "    if key is not None: #キーがある場合\n",
    "        combined_message = tf.concat(axis=1, values=[message, key])\n",
    "        #メッセージとキーを複合\n",
    "    else:#キーがNoneの場合\n",
    "        combined_message = message\n",
    "        #最初に完全結合レイヤーはメッセージのみを入力として受け取る。 \n",
    "\n",
    "    # Ensure that all variables created are in the specified collection.\n",
    "    #作成した変数が指定されたコレクションにあることを確認。\n",
    "    with tf.contrib.framework.arg_scope(\n",
    "        [tf.contrib.layers.fully_connected, tf.contrib.layers.conv2d],\n",
    "        variables_collections=[collection]):\n",
    "\n",
    "        fc = tf.contrib.layers.fully_connected(\n",
    "          combined_message,\n",
    "          TEXT_SIZE + KEY_SIZE,\n",
    "          biases_initializer=tf.constant_initializer(0.0),\n",
    "          activation_fn=None)\n",
    "\n",
    "        # Perform a sequence of 1D convolutions (by expanding the message out to 2D\n",
    "        # and then squeezing it back down).\n",
    "        fc = tf.expand_dims(fc, 2) # 2D\n",
    "        fc = tf.expand_dims(fc, 3) # 3D -- conv2d needs a depth\n",
    "        # 2,1 -> 1,2\n",
    "        conv = tf.contrib.layers.conv2d(\n",
    "          fc, 2, 2, 2, 'SAME', activation_fn=tf.nn.sigmoid)\n",
    "        # 1,2 -> 1, 2\n",
    "        conv = tf.contrib.layers.conv2d(\n",
    "          conv, 2, 1, 1, 'SAME', activation_fn=tf.nn.sigmoid)\n",
    "        # 1,2 -> 1, 1\n",
    "        conv = tf.contrib.layers.conv2d(\n",
    "          conv, 1, 1, 1, 'SAME', activation_fn=tf.nn.tanh)\n",
    "        conv = tf.squeeze(conv, 3)\n",
    "        conv = tf.squeeze(conv, 2)\n",
    "        return conv\n",
    "\n",
    "    def __init__(self):\n",
    "        in_m, in_k = self.get_message_and_key()\n",
    "        encrypted = self.model('alice', in_m, in_k)\n",
    "        decrypted = self.model('bob', encrypted, in_k)\n",
    "        eve_out = self.model('eve', encrypted, None)\n",
    "\n",
    "        self.reset_eve_vars = tf.group(\n",
    "            *[w.initializer for w in tf.compat.v1.get_collection('eve')])\n",
    "\n",
    "        optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)\n",
    "\n",
    "        # Eve's goal is to decrypt the entire message:\n",
    "        eve_bits_wrong = tf.reduce_sum(\n",
    "            tf.abs((eve_out + 1.0) / 2.0 - (in_m + 1.0) / 2.0), [1])\n",
    "        self.eve_loss = tf.reduce_sum(eve_bits_wrong)\n",
    "        self.eve_optimizer = optimizer.minimize(\n",
    "            self.eve_loss, var_list=tf.compat.v1.get_collection('eve'))\n",
    "\n",
    "        # Alice and Bob want to be accurate...\n",
    "        self.bob_bits_wrong = tf.reduce_sum(\n",
    "            tf.abs((decrypted + 1.0) / 2.0 - (in_m + 1.0) / 2.0), [1])\n",
    "        # ... and to not let Eve do better than guessing.\n",
    "        self.bob_reconstruction_loss = tf.reduce_sum(self.bob_bits_wrong)\n",
    "        bob_eve_error_deviation = tf.abs(float(TEXT_SIZE) / 2.0 - eve_bits_wrong)\n",
    "        # 7-9 bits wrong is OK too, so we squish the error function a bit.\n",
    "        # Without doing this, we often tend to hang out at 0.25 / 7.5 error,\n",
    "        # and it seems bad to have continued, high communication error.\n",
    "        bob_eve_loss = tf.reduce_sum(\n",
    "            tf.square(bob_eve_error_deviation) / (TEXT_SIZE / 2)**2)\n",
    "\n",
    "        # Rescale the losses to [0, 1] per example and combine.\n",
    "        self.bob_loss = (self.bob_reconstruction_loss / TEXT_SIZE + bob_eve_loss)\n",
    "\n",
    "        self.bob_optimizer = optimizer.minimize(\n",
    "            self.bob_loss,\n",
    "            var_list=(tf.compat.v1.get_collection('alice') + tf.compat.v1.get_collection('bob')))\n",
    "\n",
    "\n",
    "def doeval(s, ac, n, itercount):\n",
    "  \"\"\"Evaluate the current network on n batches of random examples.\n",
    "  Args:\n",
    "    s:  The current TensorFlow session\n",
    "    ac: an instance of the AdversarialCrypto class\n",
    "    n:  The number of iterations to run.\n",
    "    itercount: Iteration count label for logging.\n",
    "  Returns:\n",
    "    Bob and Eve's loss, as a percent of bits incorrect.\n",
    "  \"\"\"\n",
    "\n",
    "  bob_loss_accum = 0\n",
    "  eve_loss_accum = 0\n",
    "  for _ in xrange(n):\n",
    "    bl, el = s.run([ac.bob_reconstruction_loss, ac.eve_loss])\n",
    "    bob_loss_accum += bl\n",
    "    eve_loss_accum += el\n",
    "  bob_loss_percent = bob_loss_accum / (n * FLAGS.batch_size)\n",
    "  eve_loss_percent = eve_loss_accum / (n * FLAGS.batch_size)\n",
    "  print('%10d\\t%20.2f\\t%20.2f'%(itercount, bob_loss_percent, eve_loss_percent))\n",
    "  sys.stdout.flush()\n",
    "  return bob_loss_percent, eve_loss_percent\n",
    "\n",
    "\n",
    "def train_until_thresh(s, ac):\n",
    "    for j in xrange(MAX_TRAINING_LOOPS):\n",
    "        for _ in xrange(ITERS_PER_ACTOR):\n",
    "            s.run(ac.bob_optimizer)\n",
    "        for _ in xrange(ITERS_PER_ACTOR * EVE_MULTIPLIER):\n",
    "            s.run(ac.eve_optimizer)\n",
    "        if j % PRINT_EVERY == 0:\n",
    "            bob_avg_loss, eve_avg_loss = doeval(s, ac, EVAL_BATCHES, j)\n",
    "            if (bob_avg_loss < BOB_LOSS_THRESH and eve_avg_loss > EVE_LOSS_THRESH):\n",
    "                print('Target losses achieved.')\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def train_and_evaluate():\n",
    "  \"\"\"Run the full training and evaluation loop.\"\"\"\n",
    "\n",
    "    ac = AdversarialCrypto()\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "    with tf.compat.v1.Session() as s:\n",
    "        s.run(init)\n",
    "        print('# Batch size: ', FLAGS.batch_size)\n",
    "        print('# %10s\\t%20s\\t%20s'%(\"Iter\",\"Bob_Recon_Error\",\"Eve_Recon_Error\"))\n",
    "\n",
    "    if train_until_thresh(s, ac):\n",
    "        for _ in xrange(EVE_EXTRA_ROUNDS):\n",
    "            s.run(ac.eve_optimizer)\n",
    "        print('Loss after eve extra training:')\n",
    "            doeval(s, ac, EVAL_BATCHES * 2, 0)\n",
    "        for _ in xrange(NUMBER_OF_EVE_RESETS):\n",
    "            print('Resetting Eve')\n",
    "            s.run(ac.reset_eve_vars)\n",
    "            eve_counter = 0\n",
    "            for _ in xrange(RETRAIN_EVE_LOOPS):\n",
    "                for _ in xrange(RETRAIN_EVE_ITERS):\n",
    "                    eve_counter += 1\n",
    "                    s.run(ac.eve_optimizer)\n",
    "                doeval(s, ac, EVAL_BATCHES, eve_counter)\n",
    "            doeval(s, ac, EVAL_BATCHES, eve_counter)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  # Exit more quietly with Ctrl-C.\n",
    "  signal.signal(signal.SIGINT, signal.SIG_DFL)\n",
    "    train_and_evaluate()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.compat.v1.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の結果から\n",
    "\n",
    "\n",
    "現代のRSA暗号やSSL暗号は、コンピュータの速度の制限によって強度を担保している暗号システムであるため、計算速度が猛烈に早い量子コンピュータが本格的に実用化した場合、一瞬で解読される。\n",
    "ニューラル暗号は、コンピュータの計算速度に依存せず、復号化キーなければわからない。 　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 論文（英文）"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LEARNING TO PROTECT COMMUNICATIONS　WITH ADVERSARIAL NEURAL CRYPTOGRAPHY\n",
    "\n",
    "ABSTRACT\n",
    "We ask whether neural networks can learn to use secret keys to protect information from other neural networks. Specifically, we focus on ensuring confidentiality properties in a multiagent system, and we specify those properties in terms of an adversary. Thus, a system may consist of neural networks named Alice and Bob,\n",
    "and we aim to limit what a third neural network named Eve learns from eavesdropping on the communication between Alice and Bob. We do not prescribe specific cryptographic algorithms to these neural networks; instead, we train end-to-end, adversarially. We demonstrate that the neural networks can learn how to perform forms of encryption and decryption, and also how to apply these operations selectively in order to meet confidentiality goals.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 INTRODUCTION\n",
    "As neural networks are applied to increasingly complex tasks, they are often trained to meet endto-end objectives that go beyond simple functional specifications. These objectives include, for example, generating realistic images (e.g., (Goodfellow et al., 2014a)) and solving multiagent problems (e.g., (Foerster et al., 2016a;b; Sukhbaatar et al., 2016)). Advancing these lines of work, we show that neural networks can learn to protect their communications in order to satisfy a policy specified in terms of an adversary. \n",
    "\n",
    "Cryptography is broadly concerned with algorithms and protocols that ensure the secrecy and integrity of information. Cryptographic mechanisms are typically described as programs or Turing machines. Attackers are also described in those terms, with bounds on their complexity (e.g., limited to polynomial time) and on their chances of success (e.g., limited to a negligible probability). A mechanism is deemed secure if it achieves its goal against all attackers. For instance, an encryption algorithm is said to be secure if no attacker can extract information about plaintexts from ciphertexts. Modern cryptography provides rigorous versions of such definitions (Goldwasser & Micali, 1984). \n",
    "\n",
    "Adversaries also play important roles in the design and training of neural networks. They arise, in particular, in work on adversarial examples (Szegedy et al., 2013; Goodfellow et al., 2014b) and on generative adversarial networks (GANs) (Goodfellow et al., 2014a). In this latter context, the adversaries are neural networks (rather than Turing machines) that attempt to determine whether a sample value was generated by a model or drawn from a given data distribution. Furthermore, in contrast with definitions in cryptography, practical approaches to training GANs do not consider all possible adversaries in a class, but rather one or a small number of adversaries that are optimized by training. We build on these ideas in our work. \n",
    "\n",
    "Neural networks are generally not meant to be great at cryptography. Famously, the simplest neural networks cannot even compute XOR, which is basic to many cryptographic algorithms. Nevertheless, as we demonstrate, neural networks can learn to protect the confidentiality of their data from other neural networks: they discover forms of encryption and decryption, without being taught specific algorithms for these purposes. \n",
    "\n",
    "Knowing how to encrypt is seldom enough for security and privacy. Interestingly, neural networks can also learn what to encrypt in order to achieve a desired secrecy property while maximizing utility. Thus, when we wish to prevent an adversary from seeing a fragment of a plaintext, or from estimating a function of the plaintext, encryption can be selective, hiding the plaintext only partly.\n",
    "\n",
    "(1)------------------------------------------------------------------------------------------\n",
    "\n",
    "The resulting cryptosystems are generated automatically. In this respect, our work resembles recent research on automatic synthesis of cryptosystems, with tools such as ZooCrypt (Barthe et al., 2013), and contrasts with most of the literature, where hand-crafted cryptosystems are the norm. ZooCrypt relies on symbolic theorem-proving, rather than neural networks.\n",
    "\n",
    "Classical cryptography, and tools such as ZooCrypt, typically provide a higher level of transparency and assurance than we would expect by our methods. Our model of the adversary, which avoids quantification, results in much weaker guarantees. On the other hand, it is refreshingly simple, and it may sometimes be appropriate.\n",
    "\n",
    "Consider, for example, a neural network with several components, and suppose that we wish to guarantee that one of the components does not rely on some aspect of the input data, perhaps because of concerns about privacy or discrimination. Neural networks are notoriously difficult to explain, so it may be hard to characterize how the component functions. A simple solution is to treat the component as an adversary, and to apply encryption so that it does not have access to the information that it should not use. In this respect, the present work follows the recent research on fair representations (Edwards & Storkey, 2015; Louizos et al., 2015), which can hide or remove sensitive information, but goes beyond that work by allowing for the possibility of decryption, which supports richer dataflow structures.\n",
    "\n",
    "Classical cryptography may be able to support some applications along these lines. In particular, homomorphic encryption enables inference on encrypted data (Xie et al., 2014; Gilad-Bachrachet al., 2016). On the other hand, classical cryptographic functions are generally not differentiable, so they are at odds with training by stochastic gradient descent (SGD), the main optimization technique for deep neural networks. Therefore, we would have trouble learning what to encrypt, even if we know how to encrypt. \n",
    "\n",
    "Integrating classical cryptographic functions and, more generally, integrating other known functions and relations (e.g., (Neelakantan et al., 2015))—into neural networks remains a fascinating problem.\n",
    "\n",
    "\n",
    "Prior work at the intersection of machine learning and cryptography has focused on the generation and establishment of cryptographic keys (Ruttor, 2006; Kinzel & Kanter, 2002), and on corresponding attacks (Klimov et al., 2002). In contrast, our work takes these keys for granted, and focuses on their use; a crucial, new element in our work is the reliance on adversarial goals and training. More broadly, from the perspective of machine learning, our work relates to the application of neural networks to multiagent tasks, mentioned above, and to the vibrant research on generative models and on adversarial training (e.g., (Goodfellow et al., 2014a; Denton et al., 2015; Salimans et al., 2016; Nowozin et al., 2016; Chen et al., 2016; Ganin et al., 2015)). From the perspective of cryptography, it relates to big themes such as privacy and discrimination. While we embrace a playful, exploratory approach, we do so with the hope that it will provide insights useful for further work on these topics. \n",
    "\n",
    "Section 2 presents our approach to learning symmetric encryption (that is, shared-key encryption, in which the same keys are used for encryption and for decryption) and our corresponding results. Appendix A explains how the same concepts apply to asymmetric encryption (that is, public key encryption, in which different keys are used for encryption and for decryption). Section 3 considers selective protection. Section 4 concludes and suggests avenues for further research. Appendix B is\n",
    "a brief review of background on neural networks.\n",
    "\n",
    "\n",
    "2  LEARNING SYMMETRIC ENCRYPTION\n",
    "This section discusses how to protect the confidentiality of plaintexts using shared keys. It describes the organization of the system that we consider, and the objectives of the participants in this system. It also explains the training of these participants, defines their architecture, and presents experiments.\n",
    "\n",
    "2.1 SYSTEM ORGANIZATION\n",
    "A classic scenario in security involves three parties: Alice, Bob, and Eve. Typically, Alice and Bob wish to communicate securely, and Eve wishes to eavesdrop on their communications. Thus, the desired security property is secrecy (not integrity), and the adversary is a “passive attacker” that can intercept communications but that is otherwise quite limited: it cannot initiate sessions, inject messages, or modify messages in transit.\n",
    "(2)------------------------------------------------------------------------------------------\n",
    "\n",
    "We start with a particularly simple instance of this scenario, depicted in Figure 1, in which Alice wishes to send a single confidential message P to Bob. The message P is an input to Alice. When Alice processes this input, it produces an output C. (“P” stands for “plaintext” and “C” stands for “ciphertext”.) Both Bob and Eve receive C, process it, and attempt to recover P. We represent what they compute by PBob and PEve, respectively. Alice and Bob have an advantage over Eve: they share a secret key K. We treat K as an additional input to Alice and Bob. We assume one fresh key K per plaintext P, but, at least at this abstract level, we do not impose that K and P have the same length. \n",
    "\n",
    "For us, Alice, Bob, and Eve are all neural networks. We describe their structures in Sections 2.4 and 2.5. They each have parameters, which we write θA, θB, and θE, respectively. Since θA and θB need not be equal, encryption and decryption need not be the same function even if Alice and Bob have the same structure. As is common for neural networks, Alice, Bob, and Eve work over tuples of floating-point numbers, rather than sequences of bits. In other words, K, P, PBob, PEve, and C are all tuples of floating-point numbers. Note that, with this formulation, C, PBob, and PEve may consist of arbitrary floating-point numbers even if P and K consist of 0s and 1s. In practice, our implementations constrain these values to the range (−1, 1), but permit the intermediate values. We have explored alternatives (based on Williams’ REINFORCE algorithm (Williams, 1992) or on Foerster et al.’s discretization technique (Foerster et al., 2016b)), but omit them as they are not essential to our main points.\n",
    "\n",
    "\n",
    "This set-up, although rudimentary, suffices for basic schemes, in particular allowing for the possibility that Alice and Bob decide to rely on K as a one-time pad, performing encryption and decryption simply by XORing the key K with the plaintext P and the ciphertext C, respectively. However, we do not require that Alice and Bob function in this way—and indeed, in our experiments in Section 2.5, they discover other schemes. For simplicity, we ignore the process of generating a key from a seed. We also omit the use of randomness for probabilistic encryption (Goldwasser & Micali, 1984). Such enhancements may be the subject of further work.\n",
    "\n",
    "2.2 OBJECTIVES\n",
    "Informally, the objectives of the participants are as follows. Eve’s goal is simple: to reconstruct P\n",
    "accurately (in other words, to minimize the error between P and PEve). Alice and Bob want to communicate clearly (to minimize the error between P and PBob), but also to hide their communication from Eve. Note that, in line with modern cryptographic definitions (e.g., (Goldwasser & Micali, 1984)), we do not require that the ciphertext C “look random” to Eve. A ciphertext may even contain obvious metadata that identifies it as such. Therefore, it is not a goal for Eve to distinguish C from a random value drawn from some distribution. In this respect, Eve’s objectives contrast with common ones for the adversaries of GANs. On the other hand, one could try to reformulate Eve’s goal in terms of distinguishing the ciphertexts constructed from two different plaintexts.\n",
    "\n",
    " Given these objectives, instead of training each of Alice and Bob separately to implement some known cryptosystem (Dourlens, 1996), we train Alice and Bob jointly to communicate successfully and to defeat Eve without a pre-specified notion of what cryptosystem they may discover for this purpose.\n",
    "(3)------------------------------------------------------------------------------------------\n",
    "Much as in the definitions of GANs, we would like Alice and Bob to defeat the best possible version of Eve, rather than a fixed Eve. Of course, Alice and Bob may not win for every plaintext and every key, since knowledge of some particular plaintexts and keys may be hardwired into Eve. (For instance, Eve could always output the same plaintext, and be right at least once.) Therefore, we assume a distribution on plaintexts and keys, and phrase our goals for Alice and Bob in terms of expected values.\n",
    "\n",
    "We write A(θA, P, K) for Alice’s output on input P, K, write B(θB, C, K) for Bob’s output on input C, K, and write E(θE, C) for Eve’s output on input C. We introduce a distance function d on plaintexts. Although the exact choice of this function is probably not crucial, for concreteness we take the L1 distance d(P, P0) = Σi=1,N |Pi − P0i| where N is the length of plaintexts. We define aper-example loss function for Eve: LE(θA, θE, P, K) = d(P, E(θE, A(θA, P, K)))\n",
    "\n",
    "Intuitively, LE(θA, θE, P, K) represents how much Eve is wrong when the plaintext is P and the\n",
    "key is K. We also define a loss function for Eve over the distribution on plaintexts and keys by\n",
    "taking an expected value: LE(θA, θE) = EP,K(d(P, E(θE, A(θA, P, K))))\n",
    "\n",
    "We obtain the “optimal Eve” by minimizing this loss:OE(θA) = argminθE(LE(θA, θE))\n",
    "\n",
    "Similarly, we define a per-example reconstruction error for Bob, and extend it to the distribution on\n",
    "plaintexts and keys:\n",
    "LB(θA, θB, P, K) = d(P, B(θB, A(θA, P, K), K))\n",
    "LB(θA, θB) = EP,K(d(P, B(θB, A(θA, P, K), K)))\n",
    "We define a loss function for Alice and Bob by combining LB and the optimal value of LE:\n",
    "LAB(θA, θB) = LB(θA, θB) − LE(θA, OE(θA))\n",
    "\n",
    "This combination reflects that Alice and Bob want to minimize Bob’s reconstruction error and to maximize the reconstruction error of the “optimal Eve”. The use of a simple subtraction is somewhat arbitrary; below we describe useful variants. We obtain the “optimal Alice and Bob” by minimizingLAB(θA, θB):(OA, OB) = argmin(θA,θB) (LAB(θA, θB))\n",
    "\n",
    "We write “optimal” in quotes because there need be no single global minimum. In general, there are many equi-optimal solutions for Alice and Bob. As a simple example, assuming that the key is of the same size as the plaintext and the ciphertext, Alice and Bob may XOR the plaintext and the ciphertext, respectively, with any permutation of the key, and all permutations are equally good as long as Alice and Bob use the same one; moreover, with the way we architect our networks (see Section 2.4), all permutations are equally likely to arise. \n",
    "\n",
    "Training begins with the Alice and Bob networks initialized randomly. The goal of training is to go from that state to (OA, OB), or close to (OA, OB). We explain the training process next.\n",
    "\n",
    "2.3 TRAINING REFINEMENTS\n",
    "Our training method is based upon SGD. In practice, much as in work on GANs, our training method cuts a few corners and incorporates a few improvements with respect to the high-level description of objectives of Section 2.2. We present these refinements next, and give further details in Section 2.5. \n",
    "\n",
    "First, the training relies on estimated values calculated over “minibatches” of hundreds or thousands of examples, rather than on expected values over a distribution.\n",
    "\n",
    "We do not compute the “optimal Eve” for a given value of θA, but simply approximate it, alternating\n",
    "the training of Eve with that of Alice and Bob. Intuitively, the training may for example proceed\n",
    "roughly as follows. Alice may initially produce ciphertexts that neither Bob nor Eve understand at all. By training for a few steps, Alice and Bob may discover a way to communicate that allows Bob to decrypt Alice’s ciphertexts at least partly, but which is not understood by (the present version of)Eve. In particular, Alice and Bob may discover some trivial transformations, akin to rot13. \n",
    "(4)------------------------------------------------------------------------------------------\n",
    "Aftera bit of training, however, Eve may start to break this code. With some more training, Alice and Bob may discover refinements, in particular codes that exploit the key material better. Eve eventually finds it impossible to adjust to those codes. This kind of alternation is typical of games; the theory of continuous games includes results about convergence to equilibria (e.g., (Ratliff et al., 2013)) which it might be possible to apply in our setting. \n",
    "\n",
    "Furthermore, in the training of Alice and Bob, we do not attempt to maximize Eve’s reconstruction error. If we did, and made Eve completely wrong, then Eve could be completely right in the next iteration by simply flipping all output bits! A more realistic and useful goal for Alice and Bob is, generally, to minimize the mutual information between Eve’s guess and the real plaintext. In the case of symmetric encryption, this goal equates to making Eve produce answers indistinguishable from\n",
    "a random guess. This approach is somewhat analogous to methods that aim to prevent overtraining GANs on the current adversary (Salimans et al., 2016, Section 3.1). Additionally, we can tweak the loss functions so that they do not give much importance to Eve being a little lucky or to Bob making small errors that standard error-correction could easily address.\n",
    "\n",
    "Finally, once we stop training Alice and Bob, and they have picked their cryptosystem, we validate\n",
    "that they work as intended by training many instances of Eve that attempt to break the cryptosystem.\n",
    "Some of these instances may be derived from earlier phases in the training.\n",
    "\n",
    "2.4 NEURAL NETWORK ARCHITECTURE\n",
    "\n",
    "The Architecture of Alice, Bob, and Eve Because we wish to explore whether a general neural network can learn to communicate securely, rather than to engineer a particular method, we aimed to create a neural network architecture that was sufficient to learn mixing functions such as XOR, but that did not strongly encode the form of any particular algorithm. \n",
    "\n",
    "To this end, we chose the following “mix & transform” architecture. It has a first fully-connected (FC) layer, where the number of outputs is equal to the number of inputs. The plaintext and key bits are fed into this FC layer. Because each output bit can be a linear combination of all of the input bits, this layer enables—but does not mandate—mixing between the key and the plaintext bits.\n",
    "In particular, this layer can permute the bits. The FC layer is followed by a sequence of convolutional layers, the last of which produces an output of a size suitable for a plaintext or ciphertext.\n",
    "These convolutional layers learn to apply some function to groups of the bits mixed by the previous layer, without an a priori specification of what that function should be. Notably, the opposite order (convolutional followed by FC) is much more common in image-processing applications. Neural networks developed for those applications frequently use convolutions to take advantage of spatial locality. For neural cryptography, we specifically wanted locality—i.e., which bits to combine—to be a learned property, instead of a pre-specified one. While it would certainly work to manually pair each input plaintext bit with a corresponding key bit, we felt that doing so would be uninteresting.\n",
    "\n",
    "We refrain from imposing further constraints that would simplify the problem. \n",
    "For example, we do not tie the parameters θA and θB, as we would if we had in mind that Alice and Bob should both learn the same function, such as XOR.\n",
    "\n",
    "2.5 EXPERIMENTS\n",
    "As a proof-of-concept, we implemented Alice, Bob, and Eve networks that take N-bit random plaintext and key values, and produce N-entry floating-point ciphertexts, for N = 16, 32, and 64. Both plaintext and key values are uniformly distributed. Keys are not deliberately reused, but may reoccur because of random selection. (The experiments in Section 3 consider more interesting distributions and also allow plaintext and key values to have different sizes.) We implemented our experiments in TensorFlow (Abadi et al., 2016a;b). We ran them on a workstation with one GPU; the specific computation platform does not affect the outcome of the experiments. We plan to release the source code for the experiments.\n",
    "\n",
    "(5)------------------------------------------------------------------------------------------\n",
    "The Alice network concatenates two N-bit inputs (the plaintext and the key) into a 2N-entry vector,using −1 and 1 to represent the bit values. This vector is processed through a 2N×2N FC layer, then sent through a succession of four 1-D convolutional layers. The convolutional layers are described in terms of their window size, input depth, and output depth. Each has a “stride”—the amount by which the window is shifted at each step. The concrete layers are [4, 1, 2], [2, 2, 4], [1, 4, 4], and [1, 4, 1], with strides of 1, 2, 1, 1. Intuitively, the first layer slides a size-4 window across the 2N output elements from the FC layer, outputting two numbers (output depth 2), with stride 1. We use a sigmoid nonlinear unit after each layer except the final one. After the final layer, where the output is reduced to N elements, we use a tanh nonlinear unit. (Recall that tanh has an output domain between [−1, 1], bringing the values back to a range that can map to binary values.) The Bob network is identical to the Alice network The Eve network takes only the ciphertext as input, and thus has a first N × 2N FC layer.\n",
    "\n",
    "Training To train the networks, we use a “minibatch” size ranging from 256 to 4096 entries. Unless otherwise specified, we present the results from the training runs with 4096 entries. We use TensorFlow’s Adam (Kingma & Ba, 2014) optimizer with a learning rate of 0.0008. We do not reduce the learning rate over time because we wish Alice, Bob, and Eve to be able to continue to respond strongly to changes in other components, until Alice and Bob—hopefully—achieve a solution that is robust to additional changes in Eve.\n",
    "\n",
    "Training alternates between Alice/Bob and Eve, with Alice/Bob training for one minibatch, and then Eve training for two minibatches. We chose this ratio in order to give a slight computational edge to the adversary Eve without training it so much that it becomes excessively specific to the exact current parameters of Alice and Bob. Empirically, this value has worked well.\n",
    "\n",
    "Loss Functions Eve’s loss function is exactly as described above: the L1 distance between Eve’s guess and the input plaintext. The loss function for Alice and Bob is more complex, as indicated in Sections 2.2 and 2.3. This function has two components, related to Bob’s reconstruction error and to the eavesdropper’s success. The first component is simply the L1 distance between Bob’s output and the input plaintext. The latter component, on the other hand, is (N/2 − Eve L1 error) 2 /(N/2)2.\n",
    "\n",
    "This definition expresses the goal, described in Section 2.3, that Eve should not do better than random guessing. Accordingly, this component is minimized when half of the message bits are wrong and half are right. We choose a quadratic formula in order to place more emphasis on making Eve have a large error, and to impose less of a penalty when Eve guesses a few bits correctly, as should happen occasionally even if Eve’s guesses are effectively random. Adopting this formulation allowed us to have a meaningful per-example loss function (instead of looking at larger batch statistics), and improved the robustness of training. Its cost is that our final, trained Alice and Bob typically allow Eve to reconstruct slightly more bits than purely random guessing would achieve. We have not obtained satisfactory results for loss functions that depend linearly (rather than quadratically) on Eve’s reconstruction error. The best formulation remains an open question.\n",
    "\n",
    "Post-training Evaluation After successfully training the networks so that they cross an accuracy threshold (e.g., at most 0.05 bits of reconstruction error for Alice and Bob, with Eve achieving only 1-2 bits more than random guessing would predict), we reset the Eve network and train it from scratch 5 times, each for up to 250,000 steps, recording the best result achieved by any Eve. An Alice/Bob combination that fails to achieve the target thresholds within 150,000 steps is a training failure. If the retrained Eves obtain a substantial advantage, the solution is non-robust. Otherwise, we consider it a successful training outcome.\n",
    "\n",
    "Results Figure 2 shows, for one successful run, the evolution of Bob’s reconstruction error and Eve’s reconstruction error vs. the number of training steps for N = 16 bit plaintext and key values, using a minibatch size of 4096. Each point in the graph is the mean error across 4096 examples. An ideal result would have Bob’s reconstruction error drop to zero and Eve’s reconstruction error\n",
    "reach 8 (half the bits wrong). In this example, both reconstruction errors start high. After a period of time, Alice and Bob start to communicate quite effectively, but in a way that allows Eve to improve its understanding as well, gradually. Then, around step 10,000, Alice and Bob counter Eve’s progress. By about step 15,000, the training goals are effectively achieved. The remaining steps merely increase Eve’s reconstruction error slightly\n",
    "\n",
    "(6)------------------------------------------------------------------------------------------\n",
    "This training graph does not look like a typical result for neural networks, where monotonicity\n",
    "in the number of steps is generally expected. Instead, the dynamics of this adversarial training\n",
    "appear somewhat more reminiscent of evolutionary processes. These dynamics appear to depend on somewhat random-seeming change to cause the bits to mix slightly, but once there is some mixing, the gradient descent can rapidly drive it farther. \n",
    "\n",
    "Supporting this interpretation is the observation that training is not always successful. With N = 16, six of twenty initial runs were failures that never got Bob’s reconstruction \n",
    " error under the 0.05 threshold, or failed to drive Eve’s reconstruction error above 7.3 bits (of 16). In order to test the robustness of the other fourteen Alice/Bob combinations, we retrained Eve five times, and obtained reconstruction errors for Eve that ranged from 4.67 to 6.97 bits, with a mean of 6.1. Figure 3 shows the final reconstruction errors of Bob and of the most effective retrained Eve for those fourteen Alice/Bob combinations. If we somewhat arbitrarily define success as maintaining Bob’s reconstruction error at or under 0.05 bits, and requiring that Eve get at least 6 bits wrong, on average, then training succeeded half of the time (ten of twenty cases). \n",
    "\n",
    "Although training with an adversary is often unstable (Salimans et al., 2016), we suspect that some additional engineering of the neural network and its training may be able to increase this overall success rate. With a minibatch size of only 512, for example, we achieved a success rate of only 1/3 (vs. the 1/2 that we achieved with a minibatch size of 4096). In the future, it may be worth studying the impact of minibatch sizes, and also that of other parameters such as the learning rate. \n",
    "\n",
    "Analogous results hold in general for N = 32 and N = 64-bit keys and plaintexts; training appears to be successful somewhat more often for N = 64. Basically, the experiments for N = 32 and N = 64 indicate that there is nothing special about N = 16 which, to a cryptographer, may looksuspiciously tiny. We focus our presentation on the case of N = 16 because, first, the experiments run more rapidly, and second, it is modestly easier to examine their behavior. \n",
    "\n",
    "For one successful training run, we studied the changes in the ciphertext induced by various plaintext/key pairs. Although we did not perform an exhaustive analysis of the encryption method, we did make a few observations. First, it is key-dependent: changing the key and holding the plaintext constant results in different ciphertext output. It is also plaintext-dependent, as required for successful communication. However, it is not simply XOR. In particular, the output values are often floating-point values other than 0 and 1. Moreover, the effect of a change to either a key bit or a plaintext bit is spread across multiple elements in the ciphertext, not constrained to a single bit as it would be with XOR. A single-bit flip in the key typically induces significant changes in three to six of the 16 elements in the ciphertext, and smaller changes in other elements. Plaintext bits are similarly diffused across the ciphertext.\n",
    "\n",
    "3 LEARNING WHAT TO PROTECT\n",
    "Building on the results of Section 2, we study selective protection. In other words, we consider the question of whether neural networks can learn what information to protect, given confidentiality objectives described in terms of an adversary. In the simplest case, a plaintext may have several components; if we wish to keep the adversary from seeing one of the components, it may suffice to encrypt it. More generally, we may wish to publish some values correlated with the plaintext but prevent the adversary from calculating other values. In such scenarios, protecting information selectively while maximizing utility is both challenging and interesting.\n",
    "\n",
    "3.1 THE PROBLEM\n",
    "To test these ideas and to demonstrate the viability of selective protection, we focus on a concrete experiment. We construct an artificial dataset consisting of tuples of four values, hA, B, C, Di. We aim to build and train a system that outputs two predictions of D, given the first three values as inputs: a “true” prediction of D (that is, the most accurate possible estimate of D given hA, B, Ci), and a “privacy-preserving” estimate of D, which we call D-public, defined as the best possible estimate of D that does not reveal any information about the value of C. \n",
    "\n",
    "The system organization is essentially that of Figure 1, with Alice and Bob sharing a key, but here Alice receives hA, B, Ci and produces D public in addition to a ciphertext; both Bob and Eve have access to Alice’s outputs; Bob uses them for producing an improved estimate of D, while Eve attempts to recover C. Thus, our goal is to demonstrate that the adversarial training permits approximating D without revealing C, and that this approximation can be combined with encrypted information and with a key in order to obtain a better approximation of D.\n",
    "\n",
    "(7)------------------------------------------------------------------------------------------\n",
    "The distributions of A, B, C, and D are constructed so that there is substantial correlation between\n",
    "them. In particular, knowing D exactly would convey some information about the likely values of C. \n",
    "In our experiments, A, B, C, and D are normally distributed floating-point values with a correlation matrix imposed upon them. The specifics of how we generate A, B, C, and D are standard: we compute the Cholesky decomposition LL∗ of a 4 × 4 correlation matrix that specifies the pairwise correlations, we generate vectors of 4 normally distributed floating-point values, and then we multiply these vectors by L in order to generate values of A, B, C, and D.  \n",
    "Although A, B, C, and D do not correspond to any real-world data, these experiments are loosely inspired by real-world tasks. For example, A, B, and C may represent attributes of a user, which may in general be correlated, and D may represent a decision about the user, a prediction of the user’s behavior, or a recommendation to the user\n",
    "\n",
    "3.2 NEURAL NETWORK ARCHITECTURE AND TRAINING GOALS\n",
    "In the experiments that follow, we use an augmented version of the neural network architecture of Section 2.4. The inputs first go \n",
    "into a new FC layer (12 inputs—eight key bits and four values—and 12 outputs); the outputs of that first layer are fed into a network with the architecture of Section 2.4. Intuitively, we chose this augmented architecture because a single FC layer should be capable of predicting D from A, B, and C, as well as making a prediction decorrelated with C; and the architecture of Section 2.4 suffices to encrypt any of the output of the first layer under the key. We therefore believed this augmented architecture would be sufficient to accomplish its task, though it may be more than is necessary to do so. \n",
    "\n",
    "We train Eve with the goal of minimizing the squared error of its estimate of C. We train Alice and Bob with the goal of minimizing a linear combination of three terms: the squared error of each of the two estimates of D, and the absolute value of the covariance of Eve’s estimate of C with respect to the actual value of C. We compute this covariance on a batch of training examples, and define the loss function for Alice and Bob batch-wise.\n",
    "\n",
    "A human engineer would naturally try to design the system somewhat differently—likely first computing the desired quantities, and then encrypting the values to be hidden, relying on the encryption and decryption components developed in Section 2 as modules. We prefer instead an end-to-end approach, because our goal is to understand whether a neural network can learn to hide information selectively, given only a high-level specification (“do not leak information about C, but let people with the right key learn as much as possible about D”). In this end-to-end approach, the system does not have distinct, pre assigned units for encryption and decryption, and all components are trained jointly. In particular, although we benefit from some of the insights from Section 2, we do not rely on the components developed there. End-to-end approaches are sometimes preferred in machine learning because they can more efficiently use resources and information. In our case, this feature may mean, in particular, that the cryptographic operations are optimized for the given distribution of inputs. Nevertheless, our choices have the primary goal of maximizing insight, not efficiency\n",
    "\n",
    "3.3 RESULTS\n",
    "To understand whether the system is learning to hide information properly, we train a separate evaluator that we call “Blind Eve”, which is aware of the distribution of C. Blind Eve tries to guess C relying only upon this baseline information, whereas the real Eve also knows the intermediate output (D-public) and the ciphertext. If Eve’s reconstruction error becomes equal to that of Blind Eve, we know that Eve is not successfully extracting information from the public estimate and the ciphertext. \n",
    "\n",
    "Figure 4 shows the results of adversarial training to learn to hide C. The red “public error” line shows the average error of D-public vs. D. The green “Bob error” line shows Bob’s average reconstruction error, which drops over time until Bob is making the best possible prediction of D given the input. \n",
    "The public error becomes low, but is slightly higher than Bob’s. The blue dots show Eve’s average error improvement over Blind Eve. After a few steps of training, Eve’s error is substantially lowerthan that of Blind Eve (by 0.1–0.2). As time proceeds, Eve’s relative advantage becomes zero. Eve is not able to reconstruct any more information about C than would be possible by simply knowing the distribution of values of C.\n",
    "\n",
    "(8)------------------------------------------------------------------------------------------\n",
    "4 CONCLUSION\n",
    "In this paper, we demonstrate that neural networks can learn to protect communications. The learning does not require prescribing a particular set of cryptographic algorithms, nor indicating ways of applying these algorithms: it is based only on a secrecy specification represented by the training objectives. In this setting, we model attackers by neural networks; alternative models may perhaps be enabled by reinforcement learning. \n",
    "\n",
    "There is more to cryptography than encryption. In this spirit, further work may consider other tasks,\n",
    "for example steganography, pseudorandomnumber generation, or integrity checks. Finally, neural networks may be useful not only for cryptographic protections but also for attacks. While it seems improbable that neural networks would become great at cryptanalysis, they may be quite effective in making sense of metadata and in traffic analysis."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "APPENDIX \n",
    "A LEARNING ASYMMETRIC ENCRYPTION Paralleling Section 2, this section examines asymmetric encryption (also known as public-key encryption). It presents definitions and experimental results, but omits a detailed discussion of the objectives of asymmetric encryption, of the corresponding loss functions, and of the practical refinements that we develop for training, which are analogous to those for symmetric encryption.\n",
    "\n",
    "A.1 DEFINITIONS\n",
    "In asymmetric encryption, a secret is associated with each principal. The secret may be seen as a seed for generating cryptographic keys, or directly as a secret key; we adopt the latter view. A public key can be derived from the secret, in such a way that messages encrypted under the public key can be decrypted only with knowledge of the secret.\n",
    "\n",
    "We specify asymmetric encryption using a twist on our specification for symmetric encryption, shown in Figure 5. Instead of directly supplying the secret encryption key to Alice, we supply the secret key to a public-key generator, the output of which is available to every node. Only Bob has access to the underlying secret key. Much as in Section 2, several variants are possible, for instance to support probabilistic encryption. The public-key generator is itself a neural network, with its own parameters. The loss functions treats these parameters much like those of Alice and Bob. In training, these parameters are adjusted at the same time as those of Alice and Bob.\n",
    "\n",
    "A.2 EXPERIMENTS\n",
    "In our experiments on asymmetric encryption, we rely on the same approach as in Section 2.5. In\n",
    "particular, we adopt the same network structure and the same approach to training.\n",
    "The results of these experiments are intriguing, but much harder to interpret than those for symmetric encryption. In most training runs, the networks failed to achieve a robust outcome. Often, although it appeared that Alice and Bob had learned to communicate secretly, upon resetting and retraining Eve, the retrained adversary was able to decrypt messages nearly as well as Bob was.\n",
    "However, Figure 6 shows the results of one training run, in which even after five reset/retrain cycles, Eve was unable to decrypt messages between Alice and Bob.\n",
    "(13)-----------------------------------------------------------------------------------------\n",
    "\n",
    "Our chosen network structure is not sufficient to learn general implementations of many of the mathematical concepts underlying modern asymmetric cryptography, such as integer modular arithmetic. \n",
    "\n",
    "We therefore believe that the most likely explanation for this successful training run was that Alice and Bob accidentally obtained some “security by obscurity” (cf. the derivation of asymmetric schemes from symmetric schemes by obfuscation (Barak et al., 2012)). This belief is somewhat reinforced by the fact that the training result was fragile: upon further training of Alice and Bob, Eve was able to decrypt the messages. However, we cannot rule out that the networks trained into some set of hard-to-invert matrix operations resulting in “public-key-like” behavior. Our results suggest that this issue deserves more exploration.\n",
    "\n",
    "Further work might attempt to strengthen these results, perhaps relying on new designs of neural\n",
    "networks or new training procedures. \n",
    "A modest next step may consist in trying to learn particular asymmetric algorithms, such as lattice-based ciphers, in order to identify the required neural network structure and capacity\n",
    "\n",
    "B BACKGROUND ON NEURAL NETWORKS\n",
    "\n",
    "Most of this paper assumes only a few basic notions in machine learning and neural networks, as provided by general introductions (e.g., LeCun et al. (2015)). The following is a brief review. \n",
    "\n",
    "Neural networks are specifications of parameterized functions. They are typically constructed out of a sequence of somewhat modular building blocks. For example, the input to Alice is a vector of bits that represents the concatenation of the key and the plaintext. This vector (x) is input into a “fully-connected” layer, which consists of a matrix multiply (by A) and a vector addition (with b): Ax + b. The result of that operation is then passed into a nonlinear function, sometimes termed an “activation function”, such as the sigmoid function, or the hyperbolic tangent function, tanh. In classical neural networks, the activation function represents a threshold that determines whether a neuron would “fire” or not, based upon its inputs. This threshold, and matrices and vectors such as A and b, are typical neural network “parameters”. “Training” a neural network is the process that finds values of its parameters that minimize the specified loss function over the training inputs. \n",
    "\n",
    "Fully-connected layers are powerful but require substantial amounts of memory for a large network. An alternative to fully-connected layers are “convolutional” layers. Convolutional layers operate much like their counterparts in computer graphics, by sliding a parameterized convolution window across their input. The number of parameters in this window is much smaller than in an equivalent fully-connected layer. Convolutional layers are useful for applying the same function(s) at every point in an input. \n",
    "\n",
    "A neural network architecture consists of a graph of these building blocks (often, but not always, a DAG), specifying what the individual layers are (e.g., fully-connected or convolutional), how they are parameterized (number of inputs, number of outputs, etc.), and how they are wired. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 論文直訳"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "【NNを用いた通信の自動暗号化】\n",
    "概要\n",
    "ニューラルネットワークが秘密鍵を使用して他のニューラルネットワークから情報を保護することを学習できるかどうかを確認します。 具体的には、マルチエージェントシステムで機密性のプロパティを確保することに焦点を当て、それらのプロパティを敵の観点から指定します。 したがって、システムはアリスとボブという名前のニューラルネットワークで構成され、イブという名前の3番目のニューラルネットワークがアリスとボブ間の通信を盗聴することから学習するものを制限することを目指しています。 これらのニューラルネットワークに特定の暗号アルゴリズムを処方することはありません。 代わりに、敵対的にエンドツーエンドでトレーニングします。 ニューラルネットワークは、暗号化と復号化の形式を実行する方法、および機密性の目標を満たすためにこれらの操作を選択的に適用する方法を学習できることを示します。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "１　導入\n",
    "ニューラルネットワークはますます複雑なタスクに適用されるため、単純な機能仕様を超えるエンドツーエンドの目標を満たすようにトレーニングされることがよくあります。これらの目標には、たとえば、現実的な画像の生成（たとえば（Goodfellow et al。、2014a））およびマルチエージェント問題の解決（たとえば（Foerster et al。、2016a; b; Sukhbaatar et al。、2016））が含まれます。これらの作業ラインを前進させることで、ニューラルネットワークが敵の観点で指定されたポリシーを満たすために通信を保護することを学習できることを示します。\n",
    "\n",
    "暗号化は、情報の機密性と整合性を確保するアルゴリズムとプロトコルに広く関係しています。暗号化メカニズムは通常、プログラムまたはチューリングマシンとして記述されます。攻撃者は、それらの用語で説明され、その複雑さ（たとえば、多項式時間に制限される）および成功の可能性（たとえば、無視できる確率に制限される）に制限があります。すべての攻撃者に対して目標を達成した場合、メカニズムは安全であると見なされます。たとえば、暗号化アルゴリズムは、攻撃者が暗号文から平文に関する情報を抽出できない場合に安全であると言われます。現代の暗号化は、そのような定義の厳格なバージョンを提供します（Goldwasser＆Micali、1984）。\n",
    "\n",
    "敵は、ニューラルネットワークの設計とトレーニングでも重要な役割を果たします。それらは、特に、敵対的な例（Szegedy et al。、2013; Goodfellow et al。、2014b）および生成的敵対ネットワーク（GAN）（Goodfellow et al。、2014a）の研究で発生します。この後者のコンテキストでは、敵は（チューリングマシンではなく）ニューラルネットワークであり、サンプル値がモデルによって生成されたか、特定のデータ分布から取得されたかを判断しようとします。さらに、暗号の定義とは対照的に、GANをトレーニングするための実際的なアプローチでは、クラス内の考えられるすべての敵ではなく、トレーニングによって最適化された1人または少数の敵を考慮します。私たちはこれらのアイデアに基づいて作業を進めています。\n",
    "\n",
    "ニューラルネットワークは一般に、暗号技術に優れていることを意図していません。有名なことですが、最も単純なニューラルネットワークでは、多くの暗号化アルゴリズムの基本であるXORを計算することさえできません。それにもかかわらず、私たちが実証するように、ニューラルネットワークは、他のニューラルネットワークからデータの機密性を保護することを学ぶことができます。\n",
    "\n",
    "暗号化の方法を知っているだけでは、セキュリティとプライバシーを確保することはほとんどできません。興味深いことに、ニューラルネットワークは、ユーティリティを最大化しながら、目的の機密性を実現するために何を暗号化するかを学習することもできます。したがって、敵が平文の断片を見たり、平文の機能を推定したりするのを防ぎたい場合、暗号化は選択的であり、平文を部分的に隠すだけです。\n",
    "\n",
    "(1)------------------------------------------------------------------------------------------\n",
    "結果の暗号システムは自動的に生成されます。この点で、私たちの研究は、ZooCrypt（Barthe et al。、2013）などのツールを使用した暗号システムの自動合成に関する最近の研究に似ており、手作りの暗号システムが標準であるほとんどの文献と対照的です。 ZooCryptは、ニューラルネットワークではなく、シンボリックな定理証明に依存しています。\n",
    "\n",
    "従来の暗号化、およびZooCryptなどのツールは、通常、当社の方法で予想されるよりも高いレベルの透明性と保証を提供します。定量化を回避する敵のモデルでは、保証がはるかに弱くなります。一方、それはさわやかでシンプルであり、時には適切かもしれません。\n",
    "\n",
    "たとえば、いくつかのコンポーネントを持つニューラルネットワークを考えてみましょう。おそらくプライバシーや差別に関する懸念から、コンポーネントの1つが入力データの何らかの側面に依存しないことを保証したいとします。ニューラルネットワークは説明が難しいことで有名なので、コンポーネントがどのように機能するかを特徴付けるのは難しいかもしれません。単純な解決策は、コンポーネントを敵として扱い、暗号化を適用して、使用すべきでない情報にアクセスできないようにすることです。この点で、現在の研究は、公正な表現に関する最近の研究（Edwards＆Storkey、2015; Louizos et al。、2015）に基づいています。この研究は、機密情報を隠したり削除したりできますが、より豊富なデータフロー構造をサポートします。\n",
    "\n",
    "従来の暗号化は、これらのラインに沿った一部のアプリケーションをサポートできる場合があります。特に、準同型暗号化により、暗号化されたデータの推論が可能になります（Xie et al。、2014; Gilad-Bachrachet al。、2016）。一方、古典的な暗号関数は一般に微分可能ではないため、ディープニューラルネットワークの主な最適化手法である確率的勾配降下法（SGD）によるトレーニングとは相反します。したがって、暗号化の方法を知っていても、暗号化する対象を学習するのは困難です。\n",
    "\n",
    "古典的な暗号化機能を統合し、より一般的には、他の既知の機能と関係を統合する（たとえば（Neelakantan et al。、2015））-ニューラルネットワークに統合することは依然として魅力的な問題です。\n",
    "\n",
    "機械学習と暗号化の交差点での以前の研究は、暗号化キーの生成と確立（Ruttor、2006; Kinzel＆Kanter、2002）、および対応する攻撃（Klimov et al。、2002）に焦点を合わせてきました。対照的に、私たちの仕事はこれらのキーを当たり前のことと考え、その使用に焦点を当てています。私たちの仕事における重要な新しい要素は、敵対的な目標と訓練への依存です。より広くは、機械学習の観点から、私たちの仕事は、前述のマルチエージェントタスクへのニューラルネットワークの適用、および生成モデルと敵対的トレーニングに関する活発な研究に関するものです（例：（Goodfellow et al。、2014a; Denton et al。、2015; Salimans et al。、2016; Nowozin et al。、2016; Chen et al。、2016; Ganin et al。、2015））。暗号化の観点からは、プライバシーや差別などの大きなテーマに関連しています。私たちは遊び心のある探索的アプローチを採用していますが、これらのトピックのさらなる研究に役立つ洞察を提供することを期待してそうしています。\n",
    "\n",
    "セクション2では、対称暗号化（つまり、同じキーが暗号化と復号化に使用される共有キー暗号化）を学習するためのアプローチと、対応する結果を示します。付録Aでは、非対称暗号化（つまり、暗号化と復号化に異なるキーが使用される公開キー暗号化）に同じ概念がどのように適用されるかについて説明します。セクション3では、選択的保護について検討します。セクション4では、さらなる研究の手段をまとめて提案します。付録Bは\n",
    "ニューラルネットワークの背景の簡単なレビュー。\n",
    "\n",
    "2学習対称暗号化\n",
    "このセクションでは、共有キーを使用してプレーンテキストの機密性を保護する方法について説明します。 私たちが検討するシステムの組織と、このシステムの参加者の目的を説明しています。 また、これらの参加者のトレーニングについて説明し、アーキテクチャを定義し、実験を示します。\n",
    "\n",
    "2.1システム構成\n",
    "セキュリティの古典的なシナリオには、Alice、Bob、Eveの3つのパーティが含まれます。 通常、アリスとボブは安全な通信を望み、イブは通信を傍受したいと考えています。 したがって、目的のセキュリティプロパティは機密性（完全性ではなく）であり、攻撃者は通信を傍受できる「受動的な攻撃者」ですが、それ以外の場合は非常に制限されています。\n",
    "(2)------------------------------------------------------------------------------------------\n",
    "アリスが単一の機密メッセージPをボブに送信したい、図1に示すこのシナリオの特に単純なインスタンスから始めます。メッセージPは、アリスへの入力です。アリスはこの入力を処理するときに、出力Cを生成します（「P」は「プレーンテキスト」を表し、「C」は「暗号文」を表します）。ボブとイブの両方がCを受け取り、処理し、Pの回復を試みます。 PBobとPEveによってそれぞれ計算されるもの。アリスとボブはイブよりも有利です。秘密鍵Kを共有しています。Kをアリスとボブへの追加入力として扱います。平文Pごとに1つの新しいキーKを想定していますが、少なくともこの抽象レベルでは、KとPが同じ長さであることを強制しません。\n",
    "\n",
    "私たちにとって、アリス、ボブ、イブはすべてニューラルネットワークです。セクション2.4および2.5でそれらの構造を説明します。それぞれにパラメーターがあり、それぞれθA、θB、およびθEを記述します。 θAとθBは同じである必要はないため、AliceとBobが同じ構造を持っていても、暗号化と復号化は同じ関数である必要はありません。ニューラルネットワークでは一般的であるように、Alice、Bob、およびEveは、ビットシーケンスではなく、浮動小数点数のタプルを操作します。つまり、K、P、PBob、PEve、およびCはすべて浮動小数点数のタプルです。この定式化では、PとKが0と1で構成されている場合でも、C、PBob、およびPEveが任意の浮動小数点数で構成されることに注意してください。実際には、実装はこれらの値を範囲（-1、1）に制限しますが、中間値は許可します。代替案（ウィリアムズのREINFORCEアルゴリズム（Williams、1992）またはFoerster et al。の離散化手法（Foerster et al。、2016b））を検討しましたが、主要なポイントに不可欠ではないため省略します。\n",
    "\n",
    "\n",
    "この設定は基本的スキームですが、基本的なスキームで十分です。特に、アリスとボブがワンタイムパッドとしてKに依存する可能性を考慮して、単純にキーKとプレーンテキストPをXORすることで暗号化と復号化を実行します。それぞれ暗号文C。ただし、アリスとボブがこのように機能する必要はありません。実際、セクション2.5の実験では、他のスキームを発見します。簡単にするために、シードからキーを生成するプロセスは無視します。また、確率的暗号化のためのランダム性の使用も省略しています（Goldwasser＆Micali、1984）。このような機能強化は、今後の作業の対象になる場合があります。\n",
    "\n",
    "2.2目的\n",
    "非公式には、参加者の目的は次のとおりです。 Eveの目標は単純です：Pを再構築する\n",
    "正確に（言い換えれば、PとPEveの間のエラーを最小限に抑えるため）。アリスとボブは（PとPBobの間のエラーを最小限に抑えるために）明確に通信したいだけでなく、イブからの通信を隠したいです。最新の暗号の定義（例：（Goldwasser＆Micali、1984））に沿って、暗号文CがEveに「ランダムに見える」ことを要求しないことに注意してください。暗号文には、それを識別する明確なメタデータが含まれている場合もあります。したがって、イブがCを何らかの分布から引き出されたランダムな値と区別することは目標ではありません。この点で、イブの目標は、GANの敵の一般的な目標と対照的です。一方、2つの異なる平文から構成された暗号文を区別するという点で、Eveの目標を再定式化することができます。\n",
    "\n",
    " これらの目的を考えると、アリスとボブのそれぞれを個別にトレーニングして既知の暗号システムを実装するのではなく（Dourlens、1996）、アリスとボブを共同で訓練し、発見する暗号システムの事前に指定された概念なしで、正常に通信し、イブを倒すようにしますこの目的。\n",
    "(3)------------------------------------------------------------------------------------------\n",
    "\n",
    "GANの定義と同じように、アリスとボブは、固定イブではなく、イブの可能な限り最高のバージョンを打ち負かすことを望みます。もちろん、特定の平文とキーの知識がイブに組み込まれている可能性があるため、アリスとボブがすべての平文とすべてのキーに勝つわけではありません。 （たとえば、Eveは常に同じプレーンテキストを出力し、少なくとも1回は正しい場合があります。）したがって、プレーンテキストとキーの分布を想定し、AliceとBobの目標を期待値で表現します。\n",
    "\n",
    "入力P、Kでのアリスの出力にA（θA、P、K）を書き込み、入力C、Kでのボブの出力にB（θB、C、K）を書き込み、入力でのイブの出力にE（θE、C）を書き込みますC.平文に距離関数dを導入します。この関数の正確な選択はおそらく重要ではありませんが、具体的にはL1距離d（P、P0）=Σi= 1、N | Pi − P0i |を使用します。 Nは平文の長さです。イブの例ごとの損失関数を定義します：LE（θA、θE、P、K）= d（P、E（θE、A（θA、P、K）））\n",
    "\n",
    "直観的に、LE（θA、θE、P、K）は、平文がPであり、\n",
    "キーはKです。また、平文とキーの分布に対するイブの損失関数を次のように定義します。\n",
    "期待値を取る：LE（θA、θE）= EP、K（d（P、E（θE、A（θA、P、K））））\n",
    "\n",
    "この損失を最小化することにより、「最適なイブ」を取得します。OE（θ​​A）=argminθE（LE（θA、θE））\n",
    "\n",
    "同様に、ボブの例ごとの再構築エラーを定義し、それを上の分布に拡張します\n",
    "平文とキー：\n",
    "LB（θA、θB、P、K）= d（P、B（θB、A（θA、P、K）、K））\n",
    "LB（θA、θB）= EP、K（d（P、B（θB、A（θA、P、K）、K）））\n",
    "LBとLEの最適値を組み合わせて、アリスとボブの損失関数を定義します。\n",
    "LAB（θA、θB）= LB（θA、θB）− LE（θA、OE（θA））\n",
    "\n",
    "この組み合わせは、アリスとボブがボブの再構築エラーを最小化し、「最適なイブ」の再構築エラーを最大化することを望んでいることを反映しています。単純な減算の使用はいくぶんarbitrary意的です。以下に、有用なバリアントについて説明します。 LAB（θA、θB）:( OA、OB）= argmin（θA、θB）（LAB（θA、θB））を最小化することにより、「最適なアリスとボブ」を取得します。\n",
    "\n",
    "単一のグローバル最小値は必要ないため、引用符で「最適」を記述します。一般的に、アリスとボブには多くの等最適なソリューションがあります。簡単な例として、キーのサイズがプレーンテキストと暗号テキストと同じであると仮定すると、AliceとBobはそれぞれプレーンテキストと暗号テキストをXORし、キーの任意の順列を使用できます。アリスとボブは同じものを使用します。さらに、ネットワークを設計する方法（セクション2.4を参照）では、すべての順列が等しく発生する可能性があります。\n",
    "\n",
    "トレーニングは、アリスとボブのネットワークがランダムに初期化されることから始まります。トレーニングの目標は、その状態から（OA、OB）または（OA、OB）に近づくことです。次にトレーニングプロセスについて説明します。\n",
    "\n",
    "2.3トレーニングの改善\n",
    "私たちのトレーニング方法はSGDに基づいています。 実際には、GANの作業と同様に、このトレーニング方法では、セクション2.2の目的の高度な説明に関していくつかのコーナーをカットし、いくつかの改善を取り入れています。 次にこれらの改良点を示し、セクション2.5で詳細を説明します。\n",
    "\n",
    "まず、トレーニングは、分布の期待値ではなく、数百または数千の例の「ミニバッチ」で計算された推定値に依存しています。\n",
    "\n",
    "θAの特定の値に対して「最適なイブ」を計算するのではなく、単に近似して、交互に\n",
    "イブの訓練とアリスとボブの訓練。 直観的には、たとえばトレーニングを進めることができます\n",
    "おおよそ次のとおりです。アリスは、ボブもイブもまったく理解できない暗号テキストを最初に作成する場合があります。アリスとボブは、数ステップのトレーニングを行うことで、ボブがアリスの暗号テキストを少なくとも部分的に解読できる通信方法を発見できますが、これは（現在のバージョンの）イブによって理解されていません。特に、アリスとボブは、rot13に似た些細な変換を発見するかもしれません。\n",
    "(4)------------------------------------------------------------------------------------------\n",
    "しかし、少しのトレーニングの後、Eveはこのコードを破り始める可能性があります。アリスとボブは、さらにトレーニングを重ねることで、特にキーマテリアルをより効果的に活用するコードの改良点を発見できます。イブは、最終的にこれらのコードに適応することは不可能だと感じました。この種の交替はゲームの典型です。連続ゲームの理論には、均衡への収束に関する結果が含まれます（例（（Ratliff et al。、2013））。これは、私たちの設定に適用できる可能性があります）。\n",
    "\n",
    "さらに、アリスとボブのトレーニングでは、イブの再構成エラーを最大化しようとはしていません。もし、イブを完全に間違えたら、すべての出力ビットを反転させるだけで、次のイテレーションでイブが完全に正しくなる可能性があります！アリスとボブのより現実的で有用な目標は、一般的に、イブの推測と実際の平文の間の相互情報を最小限にすることです。対称暗号化の場合、この目標は、Eveが、\n",
    "ランダムな推測。このアプローチは、現在の敵に対する過剰なGANの防止を目的とする方法にやや似ています（Salimans et al。、2016、Section 3.1）。さらに、損失関数を微調整して、イブが少し幸運であることや、ボブが標準エラー訂正で簡単に対処できる小さなエラーを作成することをあまり重要にしないようにすることができます。\n",
    "\n",
    "最後に、AliceとBobのトレーニングを停止し、暗号システムを選択したら、検証します\n",
    "暗号システムを破壊しようとするEveの多くのインスタンスをトレーニングすることで、意図したとおりに機能すること。\n",
    "これらのインスタンスの一部は、トレーニングの初期段階から派生したものである可能性があります。\n",
    "\n",
    "2.4ニューラルネットワークアーキテクチャ\n",
    "\n",
    "アリス、ボブ、イブのアーキテクチャ特定の方法を設計するのではなく、一般的なニューラルネットワークが安全に通信できるかどうかを調査したいので、次のような混合機能を学習するのに十分なニューラルネットワークアーキテクチャを作成することを目指しました。 XOR。ただし、特定のアルゴリズムの形式を強くエンコードしていませんでした。\n",
    "\n",
    "このため、次の「ミックス＆トランスフォーム」アーキテクチャを選択しました。最初の完全接続（FC）レイヤーがあり、出力の数は入力の数に等しくなります。平文とキーのビットはこのFC層に送られます。各出力ビットはすべての入力ビットの線形結合である可能性があるため、このレイヤーはキーとプレーンテキストビットの混合を可能にしますが、必須ではありません。\n",
    "特に、このレイヤーはビットを入れ替えることができます。 FC層の後には畳み込み層のシーケンスが続き、最後の層はプレーンテキストまたは暗号文に適したサイズの出力を生成します。\n",
    "これらの畳み込み層は、前の層によって混合されるビットのグループに、その関数がどうあるべきかを事前に指定することなく、いくつかの関数を適用することを学習します。特に、画像処理アプリケーションでは、逆の順序（畳み込みにFCが続く）がはるかに一般的です。これらのアプリケーション用に開発されたニューラルネットワークは、空間の局所性を活用するために畳み込みを頻繁に使用します。ニューラル暗号化では、事前に指定されたものではなく、局所性（つまり、結合するビット）を学習済みのプロパティにすることを特に望んでいました。各入力プレーンテキストビットを対応するキービットと手動でペアにすることは確かに機能しますが、そうすることは面白くないと感じました。\n",
    "\n",
    "問題を簡素化するような制約を課すことは控えます。\n",
    "たとえば、アリスとボブの両方がXORなどの同じ関数を学習することを念頭に置いていた場合のように、パラメーターθAとθBを結び付けません。\n",
    "\n",
    "2.5実験\n",
    "概念実証として、Nビット16、32、および64に対して、Nビットのランダムなプレーンテキストとキー値を取得し、Nエントリの浮動小数点暗号テキストを生成するアリス、ボブ、およびイブのネットワークを実装しました。 キー値は均一に分散されます。 キーは意図的に再利用されるわけではありませんが、ランダムに選択されるために再発する可能性があります。 （セクション3の実験では、より興味深い分布を考慮し、プレーンテキストとキー値のサイズを変えることもできます。）TensorFlowで実験を実装しました（Abadi et al。、2016a; b）。 1つのGPUを備えたワークステーションでそれらを実行しました。 特定の計算プラットフォームは、実験の結果に影響しません。 実験用のソースコードを公開する予定です。\n",
    "\n",
    "(5)------------------------------------------------------------------------------------------\n",
    "ネットワーク構造当社のネットワークは、セクション2.4で説明されている「ミックス＆トランスフォーム」パターンに従います。\n",
    "\n",
    "アリスネットワークは、2つのNビット入力（プレーンテキストとキー）を連結して、ビット値を表すために-1と1を使用する2Nエントリベクトルにします。このベクトルは2N×2N FCレイヤーを介して処理され、4つの連続した1-D畳み込みレイヤーを介して送信されます。畳み込み層は、ウィンドウサイズ、入力深度、および出力深度の観点から説明されます。それぞれに「ストライド」、つまり各ステップでウィンドウがシフトされる量があります。具体的な層は、[4、1、2]、[2、2、4]、[1、4、4]、および[1、4、1]であり、ストライドは1、2、1、1です。直観的には、最初のレイヤーは、FCレイヤーの2N個の出力要素にサイズ4ウィンドウをスライドさせ、ストライド1で2つの数値（出力深度2）を出力します。最後のレイヤーを除く各レイヤーの後にシグモイド非線形ユニットを使用します。出力がN個の要素に削減される最終層の後、tanh非線形ユニットを使用します。 （tanhの出力ドメインは[−1、1]であり、値はバイナリ値にマッピングできる範囲に戻ります。）BobネットワークはAliceネットワークと同一です。Eveネットワークは暗号文のみを入力として受け取ります。したがって、最初のN×2N FC層があります。\n",
    "\n",
    "トレーニングネットワークをトレーニングするには、256〜4096エントリの範囲の「ミニバッチ」サイズを使用します。 特に指定がない限り、トレーニングランの結果は4096エントリで表示されます。 TensorFlowのAdam（Kingma＆Ba、2014）オプティマイザーを使用し、学習率は0.0008です。 アリスとボブが他のコンポーネントの変化に強く応答し続け、アリスとボブが（できれば）イブの追加の変化にロバストなソリューションを実現するまで、学習率を徐々に低下させません。 。\n",
    "\n",
    "トレーニングは、アリス/ボブとイブの間で交互に行われ、アリス/ボブは1つのミニバッチのトレーニングを行い、次にイブは2つのミニバッチのトレーニングを行います。 アリスとボブの正確な現在のパラメーターに過度に特定になるほど訓練することなく、敵のイブにわずかな計算エッジを与えるために、この比率を選択しました。 経験的に、この値はうまく機能しています。\n",
    "\n",
    "損失関数イブの損失関数は上記のとおりです。イブの推測と入力平文の間のL1距離です。セクション2.2および2.3に示すように、アリスとボブの損失関数はより複雑です。この関数には、ボブの再構築エラーと盗聴者の成功に関連する2つのコンポーネントがあります。最初の要素は、単純にボブの出力と入力プレーンテキスト間のL1距離です。一方、後者の成分は（N / 2 −イブL1エラー）2 /（N / 2）2です。\n",
    "\n",
    "この定義は、Eveがランダムな推測よりも優れているべきではないという、セクション2.3で説明されている目標を表しています。したがって、メッセージビットの半分が正しく、半分が正しい場合、このコンポーネントは最小化されます。 Eveに大きな誤差を持たせることを重視し、Eveの推測が事実上ランダムであっても、Eveが数ビットを正しく推測する場合のペナルティを少なくするために、2次式を選択します。この定式化を採用することにより、（より大きなバッチ統計を見る代わりに）意味のある例ごとの損失関数を得ることができ、トレーニングの堅牢性が向上しました。そのコストは、最終的に訓練されたアリスとボブが通常、イブが純粋にランダムな推測が達成するよりもわずかに多くのビットを再構築できるようにすることです。 Eveの再構成エラーに（二次関数ではなく）線形に依存する損失関数については、満足のいく結果が得られていません。最適な処方は未解決のままです。\n",
    "\n",
    "トレーニング後の評価精度のしきい値を超えるようにネットワークを正常にトレーニングした後（たとえば、アリスとボブの最大0.05ビットの再構成エラー、イブはランダムな推測が予測するよりも1-2ビットだけ多く達成）、 イブのネットワークとゼロから5回トレーニングし、それぞれ最大250,000ステップで、イブが達成した最高の結果を記録します。 150,000ステップ以内に目標のしきい値を達成できないアリス/ボブの組み合わせは、トレーニングの失敗です。 再訓練されたEvesが実質的な利点を得る場合、ソリューションは堅牢ではありません。 それ以外の場合は、トレーニングの成果として考えます。\n",
    "\n",
    "結果図2は、成功した1回の実行について、ボブの再構築エラーとイブの再構築エラーの進化と、N = 16ビットのプレーンテキストおよびキー値のトレーニングステップ数を、4096のミニバッチサイズを使用して示しています。 4096の例にわたる平均誤差。 理想的な結果は、ボブの再構成エラーがゼロになり、イブの再構成エラーが発生することです\n",
    "8に達します（ビットの半分が間違っています）。 この例では、両方の再構築エラーが高く始まります。 しばらくすると、アリスとボブは非常に効果的にコミュニケーションを開始しますが、イブも徐々に理解を深めることができます。 次に、ステップ10,000付近で、アリスとボブはイブの進歩に対抗します。 ステップ15,000程度で、トレーニングの目標は効果的に達成されます。 残りの手順は、イブの再構築エラーをわずかに増加させるだけです\n",
    "\n",
    "(6)------------------------------------------------------------------------------------------\n",
    "このトレーニンググラフは、単調性のあるニューラルネットワークの典型的な結果のようには見えません。\n",
    "通常、ステップ数が予想されます。代わりに、この敵対的トレーニングのダイナミクス\n",
    "進化プロセスを幾分連想させるように見える。これらのダイナミクスは、多少ランダムに見える変化に依存してビットをわずかに混合するように見えますが、混合が行われると、勾配降下により急速にそれをさらに遠くまで駆動できます。\n",
    "\n",
    "この解釈をサポートすることは、トレーニングが常に成功するとは限らないという観察です。 N = 16の場合、20回の初期実行のうち6回は失敗であり、ボブの再構成を得ることはありませんでした\n",
    " 0.05しきい値未満のエラー、または7.3ビット（16ビット）を超えるEveの再構築エラーを駆動できませんでした。他の14個のアリス/ボブの組み合わせの堅牢性をテストするために、Eveを5回再トレーニングし、平均が6.1である4.67から6.97ビットの範囲のEveの再構築エラーを取得しました。図3は、これらの14のアリス/ボブの組み合わせに対して、ボブと最も効果的な再訓練されたイブの最終的な再構成エラーを示しています。ボブの再構成エラーを0.05ビット以下に維持し、イブに平均で少なくとも6ビットの誤りを要求すると成功をある程度arbitrarily意的に定義した場合、トレーニングは半分の時間で成功しました（20ケースのうち10ケース）。\n",
    "\n",
    "敵とのトレーニングはしばしば不安定ですが（Salimans et al。、2016）、ニューラルネットワークとそのトレーニングの追加のエンジニアリングにより、この全体的な成功率を高めることができると思われます。たとえば、ミニバッチサイズが512のみの場合、成功率はわずか1/3でした（ミニバッチサイズ4096で達成した1/2に対して）。将来的には、ミニバッチサイズの影響、および学習率などの他のパラメーターの影響を調べる価値があるかもしれません。\n",
    "\n",
    "N = 32およびN = 64ビットのキーとプレーンテキストに対して、同様の結果が一般的に保持されます。基本的に、N = 32およびN = 64の実験は、暗号作成者にとっては非常に小さいように見えるN = 16について特別なものはないことを示しています。 N = 16の場合に焦点を当てます。これは、最初に実験がより迅速に実行され、2番目に、その動作を検証するのがやや簡単だからです。\n",
    "\n",
    "トレーニングを1回成功させるために、さまざまなプレーンテキスト/キーペアによって引き起こされる暗号テキストの変化を調査しました。暗号化方法の徹底的な分析は行いませんでしたが、いくつかの観察を行いました。まず、キーに依存します。キーを変更し、プレーンテキスト定数を保持すると、異なる暗号文出力が生成されます。また、正常な通信に必要な平文依存です。ただし、単なるXORではありません。特に、出力値は多くの場合、0と1以外の浮動小数点値です。さらに、キービットまたはプレーンテキストビットへの変更の影響は、暗号文の複数の要素に広がり、単一のビットに制限されません。 XORを使用します。キーのシングルビットフリップは通常、暗号文の16個の要素のうち3〜6個に大きな変化を、他の要素には小さな変化を引き起こします。平文ビットも同様に暗号文全体に拡散します。\n",
    "\n",
    "3保護対象の学習\n",
    "セクション2の結果に基づいて、選択的保護を研究します。言い換えれば、敵対者の観点から記述された機密性の目標を考えると、ニューラルネットワークが保護すべき情報を学習できるかどうかという問題を検討します。最も単純なケースでは、プレーンテキストに複数のコンポーネントが含まれる場合があります。敵がコンポーネントの1つを見ないようにするには、それを暗号化するだけで十分です。より一般的には、平文と相関するいくつかの値を公開したいが、敵が他の値を計算するのを防ぎたい場合があります。このようなシナリオでは、情報を選択的に保護しながら実用性を最大化することは難しく、興味深いものです。\n",
    "\n",
    "3.1問題\n",
    "これらのアイデアをテストし、選択的保護の実行可能性を実証するために、具体的な実験に焦点を当てます。 4つの値、hA、B、C、Diのタプルで構成される人工データセットを構築します。最初の3つの値を入力として与えられたDの2つの予測を出力するシステムを構築し、訓練することを目指しています。 Dの「プライバシーを保持する」推定値。これをDパブリックと呼びます。これは、Cの値に関する情報を一切公開しない、可能な限り最良のDの推定値として定義されます。\n",
    "\n",
    "システム構成は基本的に図1のもので、アリスとボブはキーを共有していますが、ここでアリスはhA、B、Ciを受け取り、暗号文に加えてDパブリックを生成します。ボブとイブの両方がアリスの出力にアクセスできます。ボブはDの改善された推定値を生成するためにそれらを使用しますが、イブはCを回復しようとします。したがって、私たちの目標は、敵対訓練がCを明らかにせずにDを近似できることを示し、この近似を暗号化された情報およびキーと組み合わせることができることを実証することですDのより良い近似を得るために。\n",
    "(7)------------------------------------------------------------------------------------------\n",
    "A、B、C、およびDの分布は、間に実質的な相関関係があるように構築されます\n",
    "それら。特に、Dを正確に知ると、Cの可能性のある値に関する情報が伝えられます。\n",
    "私たちの実験では、A、B、C、およびDは正規分布の浮動小数点値であり、相関行列が課されています。 A、B、C、およびDの生成方法の詳細は標準です。ペアワイズ相関を指定する4×4相関行列のコレスキー分解LL ∗を計算し、4つの正規分布浮動小数点値のベクトルを生成します。次に、A、B、C、Dの値を生成するために、これらのベクトルにLを掛けます。\n",
    "\n",
    "A、B、C、およびDは実際のデータには対応していませんが、これらの実験は実際のタスクに大まかに触発されています。たとえば、A、B、およびCは、一般的に相関するユーザーの属性を表し、Dはユーザーに関する決定、ユーザーの行動の予測、またはユーザーへの推奨を表すことができます。\n",
    "\n",
    "3.2ニューラルネットワークのアーキテクチャとトレーニングの目標\n",
    "以下の実験では、セクション2.4のニューラルネットワークアーキテクチャの拡張バージョンを使用します。入力が最初に行く\n",
    "新しいFCレイヤー（12個の入力-8つのキービットと4つの値-および12個の出力）へ。その最初の層の出力は、セクション2.4のアーキテクチャでネットワークに供給されます。直感的に、この拡張アーキテクチャを選択したのは、単一のFCレイヤーがA、B、およびCからDを予測し、Cに関連する予測非相関を作成できる必要があるためです。また、セクション2.4のアーキテクチャは、キーの下の最初の層の出力のいずれかを暗号化するのに十分です。したがって、この拡張アーキテクチャはそのタスクを達成するのに十分であると考えましたが、それは必要以上のことかもしれません。\n",
    "\n",
    "Cの推定値の2乗誤差を最小化する目的でEveを訓練します。3つの項の線形結合を最小化する目的でAliceとBobを訓練します。Dの2つの推定値それぞれの2乗誤差と絶対値EのCの推定値の共分散のCの実際の値に関する。トレーニングサンプルのバッチでこの共分散を計算し、アリスとボブの損失関数をバッチごとに定義します。\n",
    "\n",
    "人間のエンジニアは、当然のことながら、システムを多少異なる方法で設計しようとします。最初に必要な量を計算し、次にセクション2でモジュールとして開発した暗号化および復号化コンポーネントに依存して、非表示にする値を暗号化します代わりにエンドツーエンドのアプローチをお勧めします。なぜなら、私たちの目標は、高レベルの仕様のみが与えられた場合に、ニューラルネットワークが情報を選択的に隠すことを学ぶことができるかどうかを理解することですキーはDについてできる限り学習します」）。このエンドツーエンドのアプローチでは、システムには暗号化と復号化のために事前に割り当てられた個別のユニットがなく、すべてのコンポーネントが共同でトレーニングされます。特に、セクション2から得られたいくつかの洞察から利益を得ていますが、そこで開発されたコンポーネントに依存していません。機械学習では、リソースと情報をより効率的に使用できるため、エンドツーエンドのアプローチが好まれる場合があります。私たちの場合、この機能は、特に、入力の特定の分布に対して暗号化操作が最適化されることを意味する場合があります。それでも、私たちの選択には、効率ではなく洞察を最大化するという第一の目標があります\n",
    "\n",
    "3.3結果\n",
    "システムが情報を適切に隠すことを学習しているかどうかを理解するために、Cの分布を認識している「ブラインドイブ」と呼ばれる別の評価者をトレーニングします。ブラインドイブはこのベースライン情報のみに基づいてCを推測しようとしますが、 Eveは、中間出力（D-public）と暗号文も知っています。 Eveの再構築エラーがBlind Eveの再構築エラーと等しくなった場合、Eveは公開推定値と暗号文から情報を正常に抽出していないことがわかります。\n",
    "\n",
    "図4は、Cを隠すことを学ぶための敵対的訓練の結果を示しています。赤い「パブリックエラー」行は、DパブリックとDの平均エラーを示します。緑の「ボブエラー」行は、ボブの平均再構築エラーを示します。ボブが入力を与えられたDの可能な限り最高の予測をするまで。\n",
    "公開エラーは低くなりますが、ボブのエラーよりもわずかに高くなります。青い点は、ブラインドイブと比較したイブの平均的なエ​​ラー改善を示しています。数ステップのトレーニングの後、EveのエラーはBlind Eveのエラーよりも大幅に低くなります（0.1〜0.2）。時間の経過とともに、イブの相対的な優位性はゼロになります。 Eveは、Cの値の分布を単純に知ることによって可能になる以上に、Cに関する情報を再構築することはできません。\n",
    "\n",
    "(8)------------------------------------------------------------------------------------------\n",
    "4結論\n",
    "このホワイトペーパーでは、ニューラルネットワークが通信の保護を学習できることを示します。 学習では、特定の暗号アルゴリズムのセットを規定する必要も、これらのアルゴリズムを適用する方法を示す必要もありません。これは、トレーニングの目的で表される機密仕様のみに基づいています。 この設定では、攻撃者をニューラルネットワークでモデル化します。 代替学習はおそらく強化学習によって可能になります。\n",
    "\n",
    "暗号化には暗号化以上のものがあります。 この精神では、さらなる作業が他のタスクを考慮する場合があります。\n",
    "たとえば、ステガノグラフィ、擬似乱数生成、または整合性チェック。 最後に、ニューラルネットワークは暗号保護だけでなく、攻撃にも役立つ場合があります。 ニューラルネットワークが暗号解析で優れたものになることはありそうにないように見えますが、メタデータの意味を理解し、トラフィック分析を行うのに非常に効果的です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "付録\n",
    "学習非対称暗号化このセクションでは、非対称暗号化（公開キー暗号化とも呼ばれます）について説明します。定義と実験結果を示しますが、非対称暗号化の目的、対応する損失関数、およびトレーニング用に開発した実用的な改良の詳細な説明は省略します。これは対称暗号化の目的と類似しています。\n",
    "\n",
    "A.1定義\n",
    "非対称暗号化では、秘密が各プリンシパルに関連付けられます。秘密は、暗号化キーを生成するためのシード、または直接秘密キーと見なされる場合があります。後者のビューを採用しています。公開鍵は、公開鍵の下で暗号化されたメッセージを秘密の知識がある場合にのみ復号化できるように、秘密から導出できます。\n",
    "\n",
    "図5に示すように、対称暗号化の仕様にツイストを使用して非対称暗号化を指定します。秘密の暗号化キーをAliceに直接提供する代わりに、公開キージェネレーターに秘密キーを提供します。ノード。基礎となる秘密鍵にアクセスできるのはボブだけです。セクション2と同様に、たとえば確率的暗号化をサポートするために、いくつかの変形が可能です。公開鍵ジェネレータは、それ自体が独自のパラメータを持つニューラルネットワークです。損失関数は、これらのパラメーターをアリスとボブのパラメーターと同様に扱います。トレーニングでは、これらのパラメーターはアリスとボブのパラメーターと同時に調整されます。\n",
    "\n",
    "A.2実験\n",
    "非対称暗号化の実験では、セクション2.5と同じアプローチに依存しています。に\n",
    "特に、同じネットワーク構造とトレーニングへの同じアプローチを採用しています。\n",
    "これらの実験の結果は興味深いものですが、対称暗号化の場合よりも解釈がはるかに困難です。ほとんどのトレーニングの実行では、ネットワークは堅牢な結果を達成できませんでした。多くの場合、アリスとボブは密かに通信することを学んだように見えますが、イブをリセットして再訓練すると、再訓練された敵はボブとほぼ同じようにメッセージを解読できました。\n",
    "ただし、図6は1回のトレーニング実行の結果を示しています。5回のリセット/再トレーニングサイクルの後でも、Eveはアリスとボブの間のメッセージを解読できませんでした。\n",
    "\n",
    "(13)-----------------------------------------------------------------------------------------\n",
    "\n",
    "選択したネットワーク構造は、整数モジュラー算術など、現代の非対称暗号化の基礎となる多くの数学的概念の一般的な実装を学習するには不十分です。\n",
    "\n",
    "したがって、この成功したトレーニング実行の最も可能性の高い説明は、アリスとボブが誤って「不明瞭によるセキュリティ」を取得したことであると考えています（難読化による対称スキームからの非対称スキームの導出（Barak et al。、2012）を参照）。この信念は、トレーニング結果が脆弱であるという事実によっていくらか強化されています。アリスとボブをさらにトレーニングすると、イブはメッセージを解読できました。ただし、ネットワークが「公開キーのような」動作をもたらす、反転しにくいマトリックス演算のセットにトレーニングされたことを除外することはできません。私たちの結果は、この問題がさらなる調査に値することを示唆しています。\n",
    "\n",
    "今後の研究では、おそらく新しいデザインのニューラルに依存して、これらの結果を強化しようとするかもしれません\n",
    "ネットワークまたは新しいトレーニング手順。\n",
    "控えめな次のステップは、必要なニューラルネットワークの構造と容量を識別するために、ラティスベースの暗号などの特定の非対称アルゴリズムを学習しようとすることです。\n",
    "\n",
    "Bニューラルネットワークの背景\n",
    "\n",
    "この論文の大部分は、一般的な紹介（LeCun et al。（2015）など）で提供されているように、機械学習とニューラルネットワークの基本的な概念をほんの少しだけ想定しています。以下は簡単なレビューです。\n",
    "\n",
    "ニューラルネットワークは、パラメーター化された関数の仕様です。これらは通常、ある程度モジュール化された一連のビルディングブロックから構築されます。たとえば、Aliceへの入力は、キーとプレーンテキストの連結を表すビットのベクトルです。このベクトル（x）は、行列の乗算（Aによる）とベクトルの加算（bによる）で構成される「完全に接続された」レイヤーへの入力です。Ax+ b。その演算の結果は、シグモイド関数や双曲線正接関数tanhなどの「活性化関数」と呼ばれることもある非線形関数に渡されます。古典的なニューラルネットワークでは、活性化関数は、その入力に基づいてニューロンが「発火」するかどうかを決定するしきい値を表します。このしきい値、およびAやbなどの行列とベクトルは、典型的なニューラルネットワークの「パラメーター」です。ニューラルネットワークの「トレーニング」とは、トレーニング入力で指定された損失関数を最小化するパラメーターの値を見つけるプロセスです。\n",
    "\n",
    "完全に接続されたレイヤーは強力ですが、大規模なネットワークではかなりの量のメモリが必要です。完全に接続されたレイヤーの代替は、「畳み込み」レイヤーです。畳み込み層は、パラメーター化された畳み込みウィンドウを入力間でスライドさせることにより、コンピューターグラフィックスの対応する層とほぼ同じように動作します。このウィンドウのパラメーターの数は、同等の完全に接続されたレイヤーの場合よりもはるかに少なくなります。畳み込み層は、入力のすべてのポイントで同じ関数を適用するのに役立ちます。\n",
    "\n",
    "ニューラルネットワークアーキテクチャは、これらのビルディングブロックのグラフ（多くの場合、必ずしもではないが、DAG）で構成され、個々のレイヤーの種類（完全接続または畳み込みなど）、パラメーター化の方法（入力の数、出力など）、およびそれらの配線方法。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "domain_adaptation：ドメイン分離ネットワーク"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "「ささいな暗号化機能を学ぶための敵対者トレーニング」、論文「敵対神経暗号による通信を保護するための学習」、Abadi＆Andersen、2016年。\n",
    "\n",
    "このプログラムは、アリス、ボブ、イブと呼ばれる3つのニューラルネットワークを作成し学習する。\n",
    "\n",
    "アリスは入力を受け取りますin_m（メッセージ）、in_k（キー）および「暗号文」を出力します。\n",
    "ボブは入力in_k、暗号文を受け取り、メッセージの再構築を試みます\n",
    "Eveは、入力暗号文を受け取り、メッセージの再構築を試みる敵対的なネットワークです。\n",
    "\n",
    "主な機能は、これらのネットワークのトレーニングを試み、それらをすべてランダムなプレーンテキストとキー値で評価します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】Iris（2値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, input_shape=(4,), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.9648 - acc: 0.4844\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 0.7601 - acc: 0.5469\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 0.6639 - acc: 0.5156\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 0.6510 - acc: 0.5625\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 0s 207us/sample - loss: 0.5684 - acc: 0.7656\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.5527 - acc: 0.7656\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 0s 261us/sample - loss: 0.4938 - acc: 0.7812\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 0.4683 - acc: 0.7812\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 0.4842 - acc: 0.7188\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.4524 - acc: 0.7812\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=10,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】Iris（多値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "#OneHot\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "y_train = enc.fit_transform(y_train)\n",
    "y_test = enc.fit_transform(y_test)\n",
    "y_val = enc.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1210 19:31:19.031019 4552873408 deprecation.py:506] From /Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, input_shape=(4,), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.6381 - acc: 0.6875\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 216us/sample - loss: 0.3946 - acc: 0.7917\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 292us/sample - loss: 0.2850 - acc: 0.8438\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 412us/sample - loss: 0.2227 - acc: 0.8958\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 163us/sample - loss: 0.1172 - acc: 0.9583\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 269us/sample - loss: 0.1133 - acc: 0.9479\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 178us/sample - loss: 0.1502 - acc: 0.9375\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 257us/sample - loss: 0.1101 - acc: 0.9479\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 260us/sample - loss: 0.0637 - acc: 0.9792\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 287us/sample - loss: 0.0676 - acc: 0.9792\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=10,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba=model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "print(\"accuracy\",accuracy_score(np.argmax(y_test,axis=1),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】House PricesをKerasで学習"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]].values\n",
    "y = df[\"SalePrice\"].values\n",
    "y = np.log(y)\n",
    "X = np.log(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               600       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 20,801\n",
      "Trainable params: 20,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(200, input_dim=2, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss=\"mean_squared_error\",optimizer = tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "             metrics=[\"mse\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=1,epochs=100,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4321411340072334\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】MNISTをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From /Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.2675 - accuracy: 0.9180 - val_loss: 0.0569 - val_accuracy: 0.9815\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0851 - accuracy: 0.9749 - val_loss: 0.0418 - val_accuracy: 0.9851\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0646 - accuracy: 0.9805 - val_loss: 0.0336 - val_accuracy: 0.9880\n",
      "Epoch 4/12\n",
      "58368/60000 [============================>.] - ETA: 3s - loss: 0.0510 - accuracy: 0.9851"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
