{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint2\n",
    "## 機械学習スクラッチ入門\n",
    "#### スクラッチ\n",
    "\n",
    "ここでのスクラッチとは、NumPyなどの基本的なライブラリを組み合わせることで、scikit-learnのような応用的なライブラリと同じ機能のクラス・関数を自作することを指します。\n",
    "\n",
    "スクラッチをすることでscikit-learnなどのライブラリを動かすだけでは掴みづらい、アルゴリズムの深い理解を目指します。コーディングのスキル向上も兼ねますが、それは主な目的ではありません。\n",
    "\n",
    "以下のような効果を狙っています。\n",
    "\n",
    "新たな手法に出会った時に理論・数式を理解しやすくする\n",
    "ライブラリを使う上での曖昧さを減らす\n",
    "既存の実装を読みやすくする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"application_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[]\n",
    "for col in train.columns:\n",
    "    if train[col].dtype==\"object\":\n",
    "        categorical_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#補間・置換(train)\n",
    "null_sum = 0\n",
    "for col in train.columns:\n",
    "    #欠損の補間\n",
    "    null_sum = train[col].isnull().sum()\n",
    "    train_length = train[col].count()\n",
    "    if null_sum > 0:\n",
    "        if train[col].dtype == object:\n",
    "            train[col] = train[col].fillna(train[col].mode()[1])\n",
    "        else:\n",
    "            train[col] = train[col].fillna(train[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.iloc[:,2:]\n",
    "y=train.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oh=pd.get_dummies(X, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_splitのスクラッチ\n",
    "\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scratch_train_test_split(X, y, train_size=0.8,):\n",
    "    \"\"\"\n",
    "    検証用データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      学習データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    #ここにコードを書く\n",
    "    p=np.random.permutation(len(X))\n",
    "    randX, randy=X[p], y[p]\n",
    "    X_train, X_test=np.vsplit(randX, [int(randX.shape[0]*train_size)])\n",
    "    y_train, y_test=np.split(randy,[int(randy.size*train_size)])    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 4 1]\n",
      "[[3 3 3 3]\n",
      " [2 2 2 2]\n",
      " [4 4 4 4]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#関数作成のためのテスト\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]])\n",
    "y = np.array([1,2,3,4])\n",
    "p = np.random.permutation(len(x))\n",
    "x, y= x[p], y[p]\n",
    "print(y)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learnを用いて機械学習を行うコードを作成\n",
    "scikit-learnを使ったコードを作成していきます。\n",
    "\n",
    "検証用データの分割には問題1で作成した自作の関数を用いてください。クロスバリデーションではなくホールドアウト法で構いません。\n",
    "\n",
    "分類は3種類の手法をスクラッチします。\n",
    "\n",
    "- ロジスティック回帰\n",
    "- SVM\n",
    "- 決定木\n",
    "\n",
    "ロジスティック回帰はscikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。引数でloss=\"log\"とすることでロジスティック回帰の計算になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IRISデータロード\n",
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ir=iris.data[50:,:]\n",
    "y_ir=iris.target[50:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シンプルデータセット1作成コード\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X1 = np.concatenate((f0, f1))\n",
    "y1 = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X1= X1[random_index]\n",
    "y1 = y1[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シンプルデータセット2作成コード\n",
    "X2 = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "\n",
    "y2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。\n",
    "\n",
    "回帰は1種類をスクラッチします。\n",
    "\n",
    "- 線形回帰\n",
    "\n",
    "線形回帰は勾配降下法を用いて計算するSGDRegressorクラスを利用してください。\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの分割\n",
    "#アヤメ\n",
    "irX_train, irX_test, iry_train, iry_test=scratch_train_test_split(X_ir, y_ir, 0.8)\n",
    "#サンプルデータ１\n",
    "X1_train, X1_test, y1_train, y1_test=scratch_train_test_split(X1, y1, 0.8)\n",
    "#サンプルデータ２\n",
    "X2_train, X2_test, y2_train, y2_test=scratch_train_test_split(X2, y2, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(100, 4)\n",
      "(100,)\n",
      "(80, 4)\n",
      "(80,)\n",
      "(20, 4)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(iris.data.shape)\n",
    "print(X_ir.shape)\n",
    "print(y_ir.shape)\n",
    "print(irX_train.shape)\n",
    "print(iry_train.shape)\n",
    "print(irX_test.shape)\n",
    "print(iry_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ロジスティック回帰**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.55\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1_score:  0.0\n",
      "confusion matrix:\n",
      " [[ 0  9]\n",
      " [ 0 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#ロジスティック回帰　アヤメデータ\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "Ir=SGDClassifier()\n",
    "Ir.fit(irX_train,iry_train)\n",
    "iry_pred=Ir.predict(irX_test)\n",
    "ir_accuracy=accuracy_score(iry_test, iry_pred)\n",
    "ir_precision=precision_score(iry_test, iry_pred)\n",
    "ir_recall=recall_score(iry_test, iry_pred)\n",
    "ir_f1=f1_score(iry_test, iry_pred)\n",
    "ir_con_mat=confusion_matrix(iry_test, iry_pred)\n",
    "\n",
    "print('accuracy: ', ir_accuracy)\n",
    "print('precision: ', ir_precision)\n",
    "print('recall: ', ir_recall)\n",
    "print('f1_score: ', ir_f1)\n",
    "print('confusion matrix:\\n', ir_con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  1.0\n",
      "precision:  1.0\n",
      "recall:  1.0\n",
      "f1_score:  1.0\n",
      "confusion matrix:\n",
      " [[49  0]\n",
      " [ 0 51]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "##ロジスティック回帰　サンプルデータ１\n",
    "Ir=SGDClassifier()\n",
    "Ir.fit(X1_train,y1_train)\n",
    "y1_pred=Ir.predict(X1_test)\n",
    "\n",
    "accuracy=accuracy_score(y1_test, y1_pred)\n",
    "precision=precision_score(y1_test, y1_pred)\n",
    "recall=recall_score(y1_test, y1_pred)\n",
    "f1=f1_score(y1_test, y1_pred)\n",
    "con_mat=confusion_matrix(y1_test, y1_pred)\n",
    "\n",
    "print('accuracy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('f1_score: ', f1)\n",
    "print('confusion matrix:\\n', con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.625\n",
      "precision:  0.3333333333333333\n",
      "recall:  0.5\n",
      "f1_score:  0.4\n",
      "confusion matrix:\n",
      " [[4 2]\n",
      " [1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "##ロジスティック回帰　サンプルデータ2\n",
    "Ir=SGDClassifier()\n",
    "Ir.fit(X2_train,y2_train)\n",
    "y2_pred=Ir.predict(X2_test)\n",
    "\n",
    "accuracy=accuracy_score(y2_test, y2_pred)\n",
    "precision=precision_score(y2_test, y2_pred)\n",
    "recall=recall_score(y2_test, y2_pred)\n",
    "f1=f1_score(y2_test, y2_pred)\n",
    "con_mat=confusion_matrix(y2_test, y2_pred)\n",
    "\n",
    "print('accuracy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('f1_score: ', f1)\n",
    "print('confusion matrix:\\n', con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 4)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irX_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  1.0\n",
      "precision:  1.0\n",
      "recall:  1.0\n",
      "f1_score:  1.0\n",
      "confusion matrix:\n",
      " [[ 9  0]\n",
      " [ 0 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM　アヤメデータ\n",
    "from sklearn.svm import SVC\n",
    "Sv=SVC()\n",
    "Sv.fit(irX_train, iry_train)\n",
    "iry_pred=Sv.predict(irX_test)\n",
    "\n",
    "ir_accuracy=accuracy_score(iry_test, iry_pred)\n",
    "ir_precision=precision_score(iry_test, iry_pred)\n",
    "ir_recall=recall_score(iry_test, iry_pred)\n",
    "ir_f1=f1_score(iry_test, iry_pred)\n",
    "ir_con_mat=confusion_matrix(iry_test, iry_pred)\n",
    "\n",
    "print('accuracy: ', ir_accuracy)\n",
    "print('precision: ', ir_precision)\n",
    "print('recall: ', ir_recall)\n",
    "print('f1_score: ', ir_f1)\n",
    "print('confusion matrix:\\n', ir_con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  1.0\n",
      "precision:  1.0\n",
      "recall:  1.0\n",
      "f1_score:  1.0\n",
      "confusion matrix:\n",
      " [[49  0]\n",
      " [ 0 51]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVC サンプルデータ１\n",
    "Sv.fit(X1_train,y1_train)\n",
    "y1_pred=Sv.predict(X1_test)\n",
    "\n",
    "accuracy=accuracy_score(y1_test, y1_pred)\n",
    "precision=precision_score(y1_test, y1_pred)\n",
    "recall=recall_score(y1_test, y1_pred)\n",
    "f1=f1_score(y1_test, y1_pred)\n",
    "con_mat=confusion_matrix(y1_test, y1_pred)\n",
    "\n",
    "print('accuracy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('f1_score: ', f1)\n",
    "print('confusion matrix:\\n', con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.75\n",
      "precision:  0.5\n",
      "recall:  1.0\n",
      "f1_score:  0.6666666666666666\n",
      "confusion matrix:\n",
      " [[4 2]\n",
      " [0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVC サンプルデータ２\n",
    "\n",
    "Sv.fit(X2_train,y2_train)\n",
    "y2_pred=Sv.predict(X2_test)\n",
    "\n",
    "accuracy=accuracy_score(y2_test, y2_pred)\n",
    "precision=precision_score(y2_test, y2_pred)\n",
    "recall=recall_score(y2_test, y2_pred)\n",
    "f1=f1_score(y2_test, y2_pred)\n",
    "con_mat=confusion_matrix(y2_test, y2_pred)\n",
    "\n",
    "print('accuracy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('f1_score: ', f1)\n",
    "print('confusion matrix:\\n', con_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  1.0\n",
      "precision:  1.0\n",
      "recall:  1.0\n",
      "f1_score:  1.0\n",
      "confusion matrix:\n",
      " [[ 9  0]\n",
      " [ 0 11]]\n"
     ]
    }
   ],
   "source": [
    "#決定木　アヤメデータ\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Tr=DecisionTreeClassifier()\n",
    "Tr.fit(irX_train,iry_train)\n",
    "iry_pred=Tr.predict(irX_test)\n",
    "\n",
    "ir_accuracy=accuracy_score(iry_test,iry_pred)\n",
    "ir_precision=precision_score(iry_test,iry_pred)\n",
    "ir_recall=recall_score(iry_test,iry_pred)\n",
    "ir_f1=f1_score(iry_test,iry_pred)\n",
    "con_mat=confusion_matrix(iry_test,iry_pred)\n",
    "\n",
    "print('accuracy: ', ir_accuracy)\n",
    "print('precision: ', ir_precision)\n",
    "print('recall: ', ir_recall)\n",
    "print('f1_score: ', ir_f1)\n",
    "print('confusion matrix:\\n', ir_con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  1.0\n",
      "precision:  1.0\n",
      "recall:  1.0\n",
      "f1_score:  1.0\n",
      "confusion matrix:\n",
      " [[49  0]\n",
      " [ 0 51]]\n"
     ]
    }
   ],
   "source": [
    "#決定木　サンプルデータ１\n",
    "Tr.fit(X1_train,y1_train)\n",
    "y1_pred=Tr.predict(X1_test)\n",
    "\n",
    "accuracy=accuracy_score(y1_test, y1_pred)\n",
    "precision=precision_score(y1_test, y1_pred)\n",
    "recall=recall_score(y1_test, y1_pred)\n",
    "f1=f1_score(y1_test, y1_pred)\n",
    "con_mat=confusion_matrix(y1_test, y1_pred)\n",
    "\n",
    "print('accuracy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('f1_score: ', f1)\n",
    "print('confusion matrix:\\n', con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.625\n",
      "precision:  0.3333333333333333\n",
      "recall:  0.5\n",
      "f1_score:  0.4\n",
      "confusion matrix:\n",
      " [[4 2]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "#決定木　サンプルデータ２\n",
    "Tr.fit(X2_train,y2_train)\n",
    "y2_pred=Tr.predict(X2_test)\n",
    "\n",
    "accuracy=accuracy_score(y2_test, y2_pred)\n",
    "precision=precision_score(y2_test, y2_pred)\n",
    "recall=recall_score(y2_test, y2_pred)\n",
    "f1=f1_score(y2_test, y2_pred)\n",
    "con_mat=confusion_matrix(y2_test, y2_pred)\n",
    "\n",
    "print('accuracy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('f1_score: ', f1)\n",
    "print('confusion matrix:\\n', con_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均２乗誤差:  0.09883197736175058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#線形回帰　アヤメデータ\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "Sg=SGDRegressor()\n",
    "Sg.fit(irX_train, iry_train)\n",
    "iry_pred=Sg.predict(irX_test)\n",
    "\n",
    "#平均二乗誤差\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse=mean_squared_error(iry_test, iry_pred)\n",
    "print('平均２乗誤差: ', lin_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均二乗誤差 0.03834642479125914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#線形回帰　サンプルデータ１\n",
    "Sg.fit(X1_train, y1_train)\n",
    "y1_pred=Sg.predict(X1_test)\n",
    "\n",
    "#平均二乗誤差\n",
    "lin_mse=mean_squared_error(y1_test,y1_pred)\n",
    "print(\"平均二乗誤差\",lin_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均二乗誤差 0.21863978299683934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakaichiaki/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#線形回帰　サンプルデータ２\n",
    "Sg.fit(X2_train, y2_train)\n",
    "y2_pred=Sg.predict(X2_test)\n",
    "\n",
    "#平均二乗誤差\n",
    "lin_mse=mean_squared_error(y2_test,y2_pred)\n",
    "print(\"平均二乗誤差\",lin_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
