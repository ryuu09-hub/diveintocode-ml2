{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint アンサンブル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3種類のアンサンブル学習をスクラッチ実装していきます。そして、それぞれの効果を小さめのデータセットで確認します。\n",
    "\n",
    "ブレンディング\n",
    "\n",
    "バギング\n",
    "\n",
    "スタッキング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[: , [\"GrLivArea\" , \"YearBuilt\"]]\n",
    "y = df.loc[: , \"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "              X , y , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "lr = LinearRegression()\n",
    "svm = SVR()\n",
    "tree = DecisionTreeRegressor()\n",
    "forest = RandomForestClassifier()\n",
    "lgb = lgb.LGBMClassifier()\n",
    "xgb = xgb.XGBRegressor(colsample_bytree = 0.5, learning_rate =0.1, max_depth = 2, n_estimators = 50,subsample =  1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】ブレンディングのスクラッチ実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。\n",
    "\n",
    "精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。\n",
    "\n",
    "回帰では各モデルの平均値を最終的な出力とすることが一般的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_test , pred):\n",
    "    return mean_squared_error(y_test , pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "svm = SVR()\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "lr.fit(X_train , y_train)\n",
    "svm.fit(X_train , y_train)\n",
    "tree.fit(X_train , y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_svm = svm.predict(X_test)\n",
    "pred_tree = tree.predict(X_test)\n",
    "\n",
    "\n",
    "mse_lr = MSE(y_test , pred_lr)\n",
    "mse_svm = MSE(y_test , pred_svm)\n",
    "mse_tree = MSE(y_test , pred_tree)\n",
    "# mse_mean = (mse_lr+mse_svm+mse_tree )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰のSME : 2230150923.51\n",
      "SVMのSME : 6695022561.36\n",
      "決定木のSME : 3556182089.05\n"
     ]
    }
   ],
   "source": [
    "print(\"線形回帰のSME : {:.2f}\".format(mse_lr))\n",
    "print(\"SVMのSME : {:.2f}\".format(mse_svm))\n",
    "print(\"決定木のSME : {:.2f}\".format(mse_tree))\n",
    "# print(\"平均SME : {:.2f}\".format(mse_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [lr, svm, tree]\n",
    "# model_names = [\"Linear Regression\", \"SVM\", \"Decision Tree\"]\n",
    "# def score(X_train , X_test , y_train , y_test):\n",
    "#     for model , name in zip(models, model_names):\n",
    "#         model.fit(X_train,y_train)\n",
    "#         print(name , model.score(X_test , y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・SVMのスコアが異常に悪い\n",
    "\n",
    "・前処理やハイパーパラメーターを変えて検証していく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重み（線形回帰、SVM、決定木）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "              X , y , test_size = 0.2)\n",
    "\n",
    "lr.fit(X_train , y_train)\n",
    "svm.fit(X_train , y_train)\n",
    "tree.fit(X_train , y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_svm = svm.predict(X_test)\n",
    "pred_tree = tree.predict(X_test)\n",
    "\n",
    "pred_sum = pred_lr*0.5 + pred_svm*0.1 + pred_tree*0.4\n",
    "\n",
    "mse_lr = MSE(y_test , pred_lr)\n",
    "mse_svm = MSE(y_test , pred_svm)\n",
    "mse_tree = MSE(y_test , pred_tree)\n",
    "mse_mean = (mse_lr+mse_svm+mse_tree )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰のSME : 2376737728.10\n",
      "SVMのSME : 6037995581.75\n",
      "決定木のSME : 2087401853.87\n",
      "平均SME : 3500711721.24\n"
     ]
    }
   ],
   "source": [
    "print(\"線形回帰のSME : {:.2f}\".format(mse_lr))\n",
    "print(\"SVMのSME : {:.2f}\".format(mse_svm))\n",
    "print(\"決定木のSME : {:.2f}\".format(mse_tree))\n",
    "print(\"平均SME : {:.2f}\".format(mse_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重みを変えSMEが減少\n",
    "平均のSMEも減少した"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準化（線形回帰、SVM、決定木）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "X_std = std.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "              X_std , y , test_size = 0.2)\n",
    "\n",
    "lr.fit(X_train , y_train)\n",
    "svm.fit(X_train , y_train)\n",
    "tree.fit(X_train , y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_svm = svm.predict(X_test)\n",
    "pred_tree = tree.predict(X_test)\n",
    "\n",
    "pred_sum = pred_lr + pred_svm + pred_tree\n",
    "\n",
    "mse_lr = MSE(y_test , pred_lr)\n",
    "mse_svm = MSE(y_test , pred_svm)\n",
    "mse_tree = MSE(y_test , pred_tree)\n",
    "mse_mean = (mse_lr+mse_svm+mse_tree )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰のSME : 2045300016.00\n",
      "SVMのSME : 6527331179.54\n",
      "決定木のSME : 3061845872.23\n",
      "平均SME : 3878159022.59\n"
     ]
    }
   ],
   "source": [
    "print(\"線形回帰のSME : {:.2f}\".format(mse_lr))\n",
    "print(\"SVMのSME : {:.2f}\".format(mse_svm))\n",
    "print(\"決定木のSME : {:.2f}\".format(mse_tree))\n",
    "print(\"平均SME : {:.2f}\".format(mse_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "標準化によってもSMEが減少した"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを入れ替える（線形回帰、lgbm、決定木）\n",
    "\n",
    "SVMのスコアが悪いため、SVMとlgbmを入れ替えて実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "              X , y , test_size = 0.2)\n",
    "\n",
    "lr.fit(X_train , y_train)\n",
    "lgb.fit(X_train , y_train)\n",
    "tree.fit(X_train , y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_lgb = lgb.predict(X_test)\n",
    "pred_tree = tree.predict(X_test)\n",
    "\n",
    "pred_sum = pred_lr + pred_lgb + pred_tree\n",
    "\n",
    "mse_lr = MSE(y_test , pred_lr)\n",
    "mse_lgb = MSE(y_test , pred_lgb)\n",
    "mse_tree = MSE(y_test , pred_tree)\n",
    "mse_mean = (mse_lr+mse_lgb+mse_tree )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰のSME : 2572958708.44\n",
      "lgbのSME : 3175065942.39\n",
      "決定木のSME : 2924254432.03\n",
      "平均SME : 2890759694.29\n"
     ]
    }
   ],
   "source": [
    "print(\"線形回帰のSME : {:.2f}\".format(mse_lr))\n",
    "print(\"lgbのSME : {:.2f}\".format(mse_lgb))\n",
    "print(\"決定木のSME : {:.2f}\".format(mse_tree))\n",
    "print(\"平均SME : {:.2f}\".format(mse_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スコアが大幅に向上した\n",
    "平均値も一番優れていた"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試したこと\n",
    "・重みの初期値の変更\n",
    "・標準化\n",
    "・モデルの変更"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】バギングのスクラッチ実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バギングは入力データの選び方を多様化する方法です。\n",
    "\n",
    "学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出します。\n",
    "\n",
    "それらによってモデルをN個学習し、推定結果の平均をとります。\n",
    "\n",
    "ブレンディングと異なり、それぞれの重み付けを変えることはありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.loc[: , [\"GrLivArea\" , \"YearBuilt\"]]\n",
    "y = df.loc[: , \"SalePrice\"]\n",
    "X_train , X_test ,y_train ,  y_test = train_test_split(\n",
    "             X , y , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = np.random.choice(X_train.index , X_train.shape[0] , replace=True)#.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([236, 996, 797, ..., 628,  77, 816])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[X_t].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sme_list = []\n",
    "def bagging(model , X , y , n = 10):\n",
    "    for i in range(n):\n",
    "        X_train , X_test ,y_train ,  y_test = train_test_split(\n",
    "             X , y , test_size = 0.2)\n",
    "        X_index = np.random.choice(X_train.index , X_train.shape[0] , replace=True)\n",
    "        X_train_n = X_train.loc[X_index]\n",
    "        model.fit(X_train_n , y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        sme = mean_squared_error(y_test , pred)\n",
    "        sme_list.append(sme)\n",
    "#     print(\"スコア{}\".format(model.score(X_test , y_test)))\n",
    "    return (np.mean(sme_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:49:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:49:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:49:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:49:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:49:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:49:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:49:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:49:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:49:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:49:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7739357724.748134"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging(xgb , X , y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1044335163.388134"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6695022561.36 - 7739357724.748134"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】スタッキングのスクラッチ実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。まずは \n",
    "K0 = 3\n",
    ",\n",
    "M0 = 2\n",
    " 程度にします。\n",
    "\n",
    "《学習時》\n",
    "\n",
    "（ステージ \n",
    "0\n",
    " ）\n",
    "\n",
    "学習データを \n",
    "K\n",
    "0\n",
    " 個に分割する。\n",
    "分割した内の \n",
    "(\n",
    "K\n",
    "0\n",
    "−\n",
    "1\n",
    ")\n",
    " 個をまとめて学習用データ、残り \n",
    "1\n",
    " 個を推定用データとする組み合わせが \n",
    "K\n",
    "0\n",
    " 個作れる。\n",
    "あるモデルのインスタンスを \n",
    "K\n",
    "0\n",
    " 個用意し、異なる学習用データを使い学習する。\n",
    "それぞれの学習済みモデルに対して、使っていない残り \n",
    "1\n",
    " 個の推定用データを入力し、推定値を得る。（これをブレンドデータと呼ぶ）\n",
    "さらに、異なるモデルのインスタンスも \n",
    "K\n",
    "0\n",
    " 個用意し、同様のことを行う。モデルが \n",
    "M\n",
    "0\n",
    " 個あれば、 \n",
    "M\n",
    "0\n",
    " 個のブレンドデータが得られる。\n",
    "（ステージ \n",
    "n\n",
    " ）\n",
    "\n",
    "ステージ \n",
    "n\n",
    "−\n",
    "1\n",
    " のブレンドデータを\n",
    "M\n",
    "n\n",
    "−\n",
    "1\n",
    " 次元の特徴量を持つ学習用データと考え、 \n",
    "K\n",
    "n\n",
    " 個に分割する。以下同様である。\n",
    "（ステージ \n",
    "N\n",
    " ）＊最後のステージ\n",
    "\n",
    "ステージ \n",
    "N\n",
    "−\n",
    "1\n",
    " の \n",
    "M\n",
    "N\n",
    "−\n",
    "1\n",
    " 個のブレンドデータを\n",
    "M\n",
    "N\n",
    "−\n",
    "1\n",
    " 次元の特徴量の入力として、1種類のモデルの学習を行う。これが最終的な推定を行うモデルとなる。\n",
    "《推定時》\n",
    "\n",
    "（ステージ \n",
    "0\n",
    " ）\n",
    "\n",
    "テストデータを \n",
    "K\n",
    "0\n",
    "×\n",
    "M\n",
    "0\n",
    " 個の学習済みモデルに入力し、\n",
    "K\n",
    "0\n",
    "×\n",
    "M\n",
    "0\n",
    " 個の推定値を得る。これを \n",
    "K\n",
    "0\n",
    " の軸で平均値を求め \n",
    "M\n",
    "0\n",
    " 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "（ステージ \n",
    "n\n",
    " ）\n",
    "\n",
    "ステージ \n",
    "n\n",
    "−\n",
    "1\n",
    " で得たブレンドテストを \n",
    "K\n",
    "n\n",
    "×\n",
    "M\n",
    "n\n",
    " 個の学習済みモデルに入力し、\n",
    "K\n",
    "n\n",
    "×\n",
    "M\n",
    "n\n",
    " 個の推定値を得る。これを \n",
    "K\n",
    "n\n",
    " の軸で平均値を求め \n",
    "M\n",
    "0\n",
    " 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "（ステージ \n",
    "N\n",
    " ）＊最後のステージ\n",
    "\n",
    "ステージ \n",
    "N\n",
    "−\n",
    "1\n",
    " で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クロスバリデーション\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters = {\"n_estimators\" : [50],\n",
    "#          \"learning_rate\":[0.1,0.3,0.5],\n",
    "#         \"max_depth\": [2,3,5,10],\n",
    "#          \"subsample\":[0.5,0.8,0.9,1],\n",
    "#          \"colsample_bytree\": [0.5,1.0],\n",
    "#          }\n",
    "\n",
    "# grid = GridSearchCV(estimator = xgb , param_grid = parameters , cv = kf , scoring = \"mean_squared_error\")\n",
    "# grid.fit(preds , y_train)\n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = { \"n_estimators\":[i for i in range(10,50,10)],\n",
    "#     \"criterion\":[\"gini\",\"entropy\"],\n",
    "#     \"max_depth\":[i for i in range(1,5,1)],\n",
    "#      'min_samples_split': [2, 4, 10,12,16],\n",
    "#     \"random_state\":[3],\n",
    "#          }\n",
    "\n",
    "# grid = GridSearchCV(estimator = forest , param_grid = parameters , cv = kf , scoring = \"mean_squared_error\")\n",
    "# grid.fit(preds , y_train)\n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid.best_score_)\n",
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.loc[: , [\"GrLivArea\" , \"YearBuilt\"]]\n",
    "y = df.loc[: , \"SalePrice\"]\n",
    "X_train , X_test ,y_train ,  y_test = train_test_split(\n",
    "             X , y , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クロスバリデーション\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [lr, tree]\n",
    "# def Stacking(models , X_train , X_test , y_train):\n",
    "#     preds = []\n",
    "#     preds_test = []\n",
    "#     va_idxes = []\n",
    "#     all_preds = []\n",
    "#     kf = KFold(n_splits = 3 , random_state = 0)\n",
    "\n",
    "#     #クロスバリデーションで学習、予測を行い、予測値とインデックスを保存\n",
    "#     for i , (tr_idx , va_idx) in enumerate(kf.split(X_train)):\n",
    "#         tr_X , va_X = X_train.iloc[tr_idx] , X_train.iloc[va_idx]\n",
    "#         tr_y , va_y = y_train.iloc[tr_idx] , y_train.iloc[va_idx]\n",
    "#         for model in models:\n",
    "#             model.fit(tr_X , tr_y) #va_X , va_y)\n",
    "#             model.fit(va_X , va_y)\n",
    "#             pred = model.predict(va_X)\n",
    "#             preds.append(pred)\n",
    "#             pred_test = model.predict(X_test)\n",
    "#             preds_test.append(pred_test)\n",
    "#             va_idxes.append(va_idx)\n",
    "#     #バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n",
    "#     print(len(preds))\n",
    "#     all_preds = all_preds.append(np.array(preds[0][1]))\n",
    "# #     print(np.array(all_preds).shape)\n",
    "#     va_idxes = np.concatenate(va_idxes)\n",
    "#     preds_1 = np.concatenate(preds , axis = 0)\n",
    "#     order = np.argsort(va_idxes)\n",
    "# #     print(order)\n",
    "# #     print(preds)\n",
    "#     pred_train = preds_1[order]\n",
    "    \n",
    "#     #テストデータに対する予測値の平均をとる\n",
    "#     preds_test = np.mean(preds_test , axis = 0)\n",
    "# #     print(np.array(pred_train).shape)\n",
    "#     pred_train = pred_train.reshape(1168  , len(models))\n",
    "#     return pred_train.shape , preds_test.shape , preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = xgb.XGBRegressor(colsample_bytree = 0.5, learning_rate =0.1, max_depth = 2, n_estimators = 50,subsample =  1)\n",
    "forest = RandomForestClassifier(max_depth = 2, min_samples_split = 2, n_estimators = 40, random_state =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking(models , X_train ,X_test,y_train)\n",
    "X_std = std.fit_transform(X)\n",
    "X_std = pd.DataFrame(data = X_std)\n",
    "X_train , X_test ,y_train ,  y_test = train_test_split(\n",
    "             X_std , y , test_size = 0.2)\n",
    "#クロスバリデーション\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [xgb , forest , tree]\n",
    "def Stacking(models , X_train , X_test , y_train):\n",
    "    preds = np.array([])\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "    kf = KFold(n_splits = 3 , random_state = 0)\n",
    "\n",
    "    #クロスバリデーションで学習、予測を行い、予測値とインデックスを保存\n",
    "    for m, model in enumerate(models):\n",
    "        for i , (tr_idx , va_idx) in enumerate(kf.split(X_train)):\n",
    "            tr_X , va_X = X_train.iloc[tr_idx] , X_train.iloc[va_idx]\n",
    "            tr_y , va_y = y_train.iloc[tr_idx] , y_train.iloc[va_idx]\n",
    "            model.fit(tr_X , tr_y) #va_X , va_y)\n",
    "            model.fit(va_X , va_y)\n",
    "            pred = model.predict(va_X)\n",
    "            preds = np.append(preds , pred)\n",
    "            pred_test = model.predict(X_test)\n",
    "            preds_test = np.append(preds_test , pred_test)\n",
    "            va_idxes.append(va_idx)\n",
    "    #バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n",
    "    preds = preds.reshape(1168 , len(models) )\n",
    "    preds_test = preds_test.reshape(292 , 9)\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    #preds = np.concatenate(preds , axis = 0)\n",
    "    order = np.argsort(va_idxes)\n",
    "#    pred_train = preds[order]\n",
    "    \n",
    "    #テストデータに対する予測値の平均をとる\n",
    "    preds_test_1 = np.mean(preds_test[: , :3] , axis = 1).reshape(-1,1)\n",
    "    preds_test_2 = np.mean(preds_test[: , 3:6] , axis = 1).reshape(-1,1)\n",
    "    preds_test_3 = np.mean(preds_test[: , 6:] , axis = 1).reshape(-1,1)\n",
    "    preds_test_sum = np.concatenate([preds_test_1 , preds_test_2 , preds_test_3] , axis=1)\n",
    "#     pred_train = pred_train.reshape(1168  , len(models))\n",
    "    return preds_test_sum , preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:07:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:07:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:07:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:07:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:07:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:07:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "preds_test , preds =Stacking(models , X_train ,X_test,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 3)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train , X_test , y_train , model):\n",
    "    model.fit(preds , y_train)\n",
    "    pred = model.predict(preds_test)\n",
    "    sme = mean_squared_error(y_test , pred)\n",
    "    return sme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5768563036.167334"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(preds , preds_test , y_train , lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
