{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint9\n",
    "## ニューラルネットワークスクラッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**データ読み込み**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前処理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "X_train=X_train.reshape(-1,784)\n",
    "X_test=X_test.reshape(-1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#データ可視化\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image,'gray',vmin=0, vmax=255)\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "#print(image) # 値を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#グレースケールの標準化\n",
    "X_train=X_train.astype(np.float)\n",
    "X_test=X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ニューラルネットワークで多クラス分類を行う際には one-hot表現 に変換\n",
    "enc=OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "y_train_one_hot=enc.fit_transform(y_test[:,np.newaxis])\n",
    "y_test_one_hot=enc.transform(y_test[:,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データ分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークスクラッチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まずは写経してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetMLP(object):\n",
    "    \"\"\"\n",
    "    多層パーセプトロンの実装クラス\n",
    "    \n",
    "    Perameters\n",
    "    ----------\n",
    "    \n",
    "    n_hidden : int (デフォルト：３０)\n",
    "    　隠れユニットの個数\n",
    "    12 : float (デフォルト:0.)\n",
    "    　L2正則化のλパラメータ\n",
    "     12=0の場合は正則化なし\n",
    "    epochs : int (デフォルト:100)\n",
    "    　トレーニングの回数\n",
    "    eta : flost (デフォルト:0.001)\n",
    "    　学習率\n",
    "    shuffle : bool (デフォルト:1)\n",
    "    　Tureの場合、循環を避けるためにエポックごとにトレーニングデータをシャッフル\n",
    "    minibatch_size : int (デフォルト:True)\n",
    "    　ミニバッチあたりのトレーニングサンプルの個数\n",
    "    seed : int (デフォルト : None)\n",
    "    　重みとシャッフルを初期化するための乱数シード\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    eval_ : dict\n",
    "    　トレーニングのエポックごとに、コスト、トレーニングの正解率、検証の正解率を収集するディクショナリ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,n_hidden=30, 12=0., epochs=100, eta=0.001,\n",
    "                 shuffle=True, minibatch_size=1,seed=None):\n",
    "        \"\"\"NeuralNetMLPの初期化\"\"\"\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.12 = 12\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "        \n",
    "    def _onehot(self, y, n_classes):\n",
    "        \"\"\"\n",
    "        ラベルをone-hotにエンコード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 配列, shape = [n_samples]\n",
    "          目的変数の値\n",
    "        \n",
    "        return\n",
    "        ----------\n",
    "        onehot : 配列, shape = (n_samples, n_labels)\n",
    "        \"\"\"\n",
    "        \n",
    "        onehot = np.zeros((n_classes, y.shape[0]))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1.\n",
    "            \n",
    "            return onehot.T\n",
    "        \n",
    "    def _sigmoid(seif, z):\n",
    "        \"\"\"ロジスティック関数（シグモイド）を計算\"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, 250, 250)))\n",
    "        \n",
    "    def _forward(self, X):\n",
    "        \"\"\"フォワードプロパゲーションのステップを計算\"\"\"\n",
    "        #ステップ１：隠れ層の総入力\n",
    "        #[n_samples, n_features] dot [n_features, n_hidden]\n",
    "        #->[n_samples, n_hidden]\n",
    "        z_h = np.dot(X,self.w_h) + self.b_h\n",
    "        \n",
    "        #ステップ２：隠れ層の活性化関数\n",
    "        a_h = self._sigmoid(z_h)\n",
    "        \n",
    "        #ステップ３：出力層の総入力\n",
    "        #[n_samples, n_hidden] dot [n_hidden, n_classlabels]\n",
    "        #->[n_samples, n_classlabels]\n",
    "        z_out = np.dot(a_h, self.w_out)\n",
    "        \n",
    "        #ステップ４：出力層の活性化関数\n",
    "        a_out = self._sigmoid(z_out)\n",
    "        \n",
    "        return z_h, a_h, z_out, a_out\n",
    "    \n",
    "    def _compute_cost(self, y_enc, output):\n",
    "        \"\"\"\n",
    "        コスト関数を計算\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_enc : 配列, shape = (n_samples, n_labels)\n",
    "          one-hot表現にエンコードされたクラスラベル\n",
    "        output : 配列, shape = [n_samples, n_output_units]\n",
    "          出力層の活性化関数（フォワードプロパゲーション）\n",
    "        \n",
    "        return\n",
    "        ---------\n",
    "        cost : float\n",
    "          正規化されたコスト\n",
    "        \"\"\"\n",
    "        \n",
    "        L2_term = (self.12 * (np.sum(self.w_h **2.) +\n",
    "                              np.sum(self.w_out ** 2.)))\n",
    "        \n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1. - y_enc) * np.log(1. - output)\n",
    "        cost = np.sum(term1 - term2) + L2_term\n",
    "        \n",
    "        #活性化関数の値がより極端である。(0または１に近い)他のデータセットに対して\n",
    "        #このコスト関数を適用する場合、現時点の実装では、PythonとNumpyの値において\n",
    "        #数値的な不安定さが原因で、\"ZeroDivisionError\"が発生することがある。\n",
    "        #つまり、このコードは（未定義である）log(0)の評価を試みる。\n",
    "        #この問題に対処するには、log関数に渡される活性関数の値に\n",
    "        #小さな定数値を足すと良いかもしれない。\n",
    "        #ex)\n",
    "        #term1 = -y_enc * (np.log(output + 1e-5))\n",
    "        #term2 = (1. - y_enc) * np.log(1. - output + 1e-5)\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        parameters\n",
    "        ----------\n",
    "        X : 配列, shape = [n_samples, n_features]\n",
    "          元の特徴量が設定された入力層\n",
    "          \n",
    "        return :\n",
    "        ---------\n",
    "        y_pred : 配列, shape = [n_samples]\n",
    "          予測されたクラスラベル\n",
    "        \"\"\"\n",
    "        \n",
    "        z_h, a_h, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\"\n",
    "        トレーニングデータから重みを学習\n",
    "        \n",
    "        parameters\n",
    "        ----------\n",
    "        X_train : 配列, shape = [n_samples, n_featues]\n",
    "          元の特徴量が設定された入力層\n",
    "        y_train : 配列, shape = [n_samples]\n",
    "        　目的地のクラスラベル\n",
    "        X_valid : 配列, shape = [n_samples, n_featues]\n",
    "          トレーニング時の検証に使用するサンプル特徴量\n",
    "        y_valid : 配列, shape = [n_samples]\n",
    "          トレーニング時の検証に使用するサンプルラベル\n",
    "        \n",
    "        return :\n",
    "        ----------\n",
    "        self\n",
    "    \n",
    "        \"\"\"\n",
    "        \n",
    "        #クラスラベルの個数\n",
    "        n_output = np.unique(y_train).shape[0]\n",
    "        \n",
    "        n_features = X_train.shape[1]\n",
    "        \n",
    "        ############\n",
    "        #重みの初期化\n",
    "        ############\n",
    "        \n",
    "        #入力層　-> 隠れ層の重み\n",
    "        self.b_h = np.zeros(self.n_hidden)\n",
    "        self.w_h = np.random.normal(loc=0.0, scale=0.1,\n",
    "                                   size=(self.n_hidden, n_output))\n",
    "        \n",
    "        #書式設定\n",
    "        epoch_strlen = len(str(self.epochs))\n",
    "        self.eval_ = {'cost':[], 'train_acc':[], 'valid_acc':[]}\n",
    "        \n",
    "        y_train_enc = self._onehot(y_train, n_output)\n",
    "        \n",
    "        #エポック数だけトレーニングを繰り返す\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            #ミニバッチの反復処理（イテレーション）\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "            \n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "            \n",
    "            for start_idx in range\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ミニバッチ処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練用データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】重みの初期値を決めるコードの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "sigma = 0.01 # ガウス分布の標準偏差\n",
    "W1 = sigma * np.rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】フォワードプロパゲーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
