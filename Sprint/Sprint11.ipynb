{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Sprint11\n",
    "## 1次元の畳み込みニューラルネットワークスクラッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train), (X_test,y_test)=mnist.load_data()\n",
    "X_train,X_test=X_train.reshape(-1,784),X_test.reshape(-1,784)\n",
    "X_train,X_test=X_train.astype(float)/255,X_test.astype(float)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "y_train=enc.fit_transform(y_train[:,np.newaxis])\n",
    "y_test=enc.transform(y_test[:,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "■1次元畳み込み層とは\n",
    "CNNでは画像に対しての2次元畳み込み層が定番ですが、ここでは理解しやすくするためにまずは1次元畳み込み層を実装します。1次元畳み込みは実用上は自然言語や波形データなどの 系列データ で使われることが多いです。\n",
    "\n",
    "畳み込みは任意の次元に対して考えることができ、立体データに対しての3次元畳み込みまではフレームワークで一般的に用意されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    XavierInitializerクラス\n",
    "    ※シグモイド関数やハイパボリックタンジェント関数のとき\n",
    "    \"\"\"\n",
    "    def __init__(self,n_nodes1):\n",
    "        self.sigma=1/np.sqrt(n_nodes1)\n",
    "       \n",
    "    def W(self, filter_size):\n",
    "        W=self.sigma*np.random.randn(filter_size)\n",
    "        return W\n",
    "    \n",
    "    def B(self):\n",
    "        B=self.sigma*np.random.randn()\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    最適化手法（AdaGrad）\n",
    "    ある層の重みやバイアスの更新\n",
    "    Parameters\n",
    "    ----------\n",
    "    layer : 更新前の層のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self,lr=0.01):\n",
    "        self.lr=lr\n",
    "        self.hW=1\n",
    "        self.hB=1\n",
    "        \n",
    "    def update(self, layer):\n",
    "        self.hW+=layer.dW\n",
    "        self.hB+=layer.dB\n",
    "#         layer.W-=self.lr*(1/np.sqrt(self.hW))*layer.dW\n",
    "#         layer.B-=self.lr*(1/np.sqrt(self.hB))*layer.dB\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    def update(self,layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        \n",
    "        layer.W-=self.lr*layer.dW\n",
    "        layer.B-=self.lr*layer.dB\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。\n",
    "\n",
    "ここでは パディング は考えず、ストライド も1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    シンプルな１次元畳込み層\n",
    "    Parameters\n",
    "    ----------\n",
    "    w : \n",
    "      フィルター\n",
    "    b : \n",
    "      バイアス\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    straide : ストライド\n",
    "    padding : パディング数\n",
    "    \"\"\"\n",
    "    def __init__(self,w,b,initializer=XavierInitializer,optimizer=AdaGrad,stride=1,padding=0,input_size=4,filter_size=3):\n",
    "        self.optimizer = optimizer()\n",
    "        self.n_nodes=input_size\n",
    "        self.initializer=initializer(self.n_nodes)\n",
    "        # 初期化\n",
    "        self.W=w\n",
    "        self.B=b\n",
    "        self.stride=stride\n",
    "        self.padding=padding\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.a=X\n",
    "        self.n_out=self.N_Out()\n",
    "        \n",
    "        #インデックス取得\n",
    "        self.idx=np.array([np.arange(i,i+len(self.W)) for i in range(self.n_out)])\n",
    "        A=(self.a[self.idx]*w).sum(axis=1)+b\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dB=dA.sum(axis=0)\n",
    "        self.dW=np.dot(dA,self.a[self.idx])\n",
    "\n",
    "        dZ=np.zeros((len(self.a)))\n",
    "        for j in range(len(dA)):\n",
    "            temp=0\n",
    "            for s in range(len(self.W)):\n",
    "                if j-s<0 or j-s>n_out-1:\n",
    "                    pass\n",
    "            else:\n",
    "                temp+=dA[j-s]*self.W[s]\n",
    "            dZ[j]=temp\n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ\n",
    "    \n",
    "    #1次元畳み込み後の出力サイズの計算\n",
    "    def N_Out(self):\n",
    "        return int(((self.a.shape[0]+2*self.padding-len(self.W))/self.stride)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#テスト用に変数を仮定\n",
    "x = np.array([1,2,3,4])#入力\n",
    "w = np.array([3, 5, 7])#重み=フィルタ\n",
    "b = np.array([1])#バイアス\n",
    "n_out=2#出力サイズ\n",
    "\n",
    "#フォワードプロパゲーション\n",
    "def forward(x,w,b,n_out):\n",
    "    #インデックス取得＋２次元配列へ\n",
    "    idx=np.array([np.arange(i,i+len(w)) for i in range(n_out)])\n",
    "    #出力作成\n",
    "    a=(x[idx]*w).sum(axis=1)+b #np.array([35, 50])\n",
    "    return a,idx\n",
    "\n",
    "#テスト\n",
    "a,idx=forward(x,w,b,n_out)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テスト用に変数を仮定\n",
    "delta_b = np.array([30])\n",
    "delta_w = np.array([50, 80, 110])\n",
    "delta_x = np.array([30, 110, 170, 140])\n",
    "delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dB:30\n",
      " dW:[ 50  80 110]\n",
      " dZ:[ 30. 110. 170. 140.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#バックワード\n",
    "def backward(x,w,idx):\n",
    "    delta_b=delta_a.sum(axis=0) #np.array([30])\n",
    "    delta_w=np.dot(delta_a,x[idx]) #np.array([50,80,110])\n",
    "    delta_x=np.zeros((len(x)))\n",
    "    for j in range(len(delta_x)):\n",
    "        temp=0\n",
    "        for s in range(len(w)):\n",
    "            if j-s<0 or j-s>n_out-1:\n",
    "                pass\n",
    "            else:\n",
    "                temp+=delta_a[j-s]*w[s]\n",
    "            delta_x[j]=temp\n",
    "    return delta_b,delta_w,delta_x\n",
    "\n",
    "#テスト\n",
    "dB,dW,dZ=backward(x,w,idx)\n",
    "print(\"dB:{}\\n\".format(dB),\n",
    "     \"dW:{}\\n\".format(dW),\n",
    "     \"dZ:{}\\n\".format(dZ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot cast ufunc subtract output from dtype('float64') to dtype('int64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8326fbf8a0a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msc1d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSimpleConv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msc1d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msc1d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-2890543900c6>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dA)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# 更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a76b6864459c>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhW\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhB\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast ufunc subtract output from dtype('float64') to dtype('int64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "#クラスでも確認\n",
    "sc1d=SimpleConv1d(w,b)\n",
    "sc1d.forward(x)\n",
    "sc1d.backward(delta_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】1次元畳み込み後の出力サイズの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def N_Out(X,W,padding,stride):\n",
    "        return ((X.shape[0]+2*padding-len(W))/stride)+1\n",
    "    \n",
    "#テスト\n",
    "N_Out(x,w,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】小さな配列での1次元畳み込み層の実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dB:30\n",
      " dW:[ 50  80 110]\n",
      " dZ:[ 30. 110. 170. 140.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "#フォワード\n",
    "a,idx=forward(x,w,b,n_out)\n",
    "a\n",
    "\n",
    "#バックワード\n",
    "dB,dW,dZ=backward(x,w,idx)\n",
    "print(\"dB:{}\\n\".format(dB),\n",
    "     \"dW:{}\\n\".format(dW),\n",
    "     \"dZ:{}\\n\".format(dZ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#工夫\n",
    "a = np.empty((2, 3))\n",
    "indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
    "indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
    "\n",
    "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
    "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
    "a = a.sum(axis=1)\n",
    "\n",
    "x = np.array([1, 2, 3, 4])\n",
    "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n",
    "x[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self,w,b,stride=1,padding=0):\n",
    "        self.W = w\n",
    "        self.B = b\n",
    "        self.stride=stride\n",
    "        self.padding=padding\n",
    "        self.out_put_size=\n",
    "        self.\n",
    "         \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.A=X\n",
    "        #インデックス取得\n",
    "        self.idx=np.array([np.arange(i,i+len(self.W)) for i in range(self.out_put_size)])\n",
    "        A=(X[idx]*w).sum(axis=1)+b\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dB=dA.sum(axis=0)\n",
    "        self.dW=np.dot(dA,self.A[self.idx])\n",
    "\n",
    "        dZ=np.zeros((len(self.A)))\n",
    "        for j in range(len(dA)):\n",
    "            temp=0\n",
    "            for j in range(len(self.W)):\n",
    "                if j-s<0 or j-s>n_out-1:\n",
    "                    pass\n",
    "            else:\n",
    "                temp+=dA[j-s]*self.W[s]\n",
    "            dZ[j]=temp\n",
    "\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_Out(x):\n",
    "        return int(((x.shape[0]+2*padding-len(self.W))/self.stride)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）\n",
    "n_out_put=\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    def backward(self, dA):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class CNN2dim_FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, w, b , optimizer,stride, padding):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        #init = initializer\n",
    "        #self.W = init.W(num_filter)\n",
    "        #self.B = init.B(num_bias)\n",
    "        self.W = w\n",
    "        self.B = b\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.A = X\n",
    "        output_size, chanel_size, filter_size = self.W.shape\n",
    "        feature_size = self.A.shape[1]\n",
    "\n",
    "        a = np.zeros([output_size, feature_size - 2])\n",
    "        for output in range(output_size):\n",
    "            for j in range(filter_size - 1):\n",
    "                sig = 0\n",
    "                for chanel in range(chanel_size):\n",
    "                    for i in range(filter_size):\n",
    "                        sig += X[chanel, i+j] * self.W[output, chanel, j]\n",
    "                a[output, j] = sig + b[output]\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "        \n",
    "        return a\n",
    "\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.n_out = N_OUT(self.stride, self.padding, self.W, self.A)\n",
    "        self.LB = np.sum(dA, axis=1)\n",
    "        \n",
    "        output_size, chanel_size, filter_size = self.W.shape\n",
    "        feature_size = self.A.shape[1]\n",
    "        \n",
    "        #LWの計算\n",
    "        self.LW = np.zeros_like(self.W)\n",
    "        for output in range(output_size):\n",
    "            for chanel in range(chanel_size):\n",
    "                for i in range(filter_size):\n",
    "                    for j in range(filter_size -1):\n",
    "                        self.LW[output, chanel, i] += dA[output, j]*self.A[chanel, j+i]\n",
    "\n",
    "                 \n",
    "                            \n",
    "        #dZの計算\n",
    "        dZ = np.zeros_like(self.A)\n",
    "        for output in range(output_size):\n",
    "            for chanel in range(chanel_size):\n",
    "                for j in range(feature_size):\n",
    "                    sigma=0\n",
    "                    for s in range(filter_size):\n",
    "                        if j - s < 0 or j - s > self.n_out -1:\n",
    "                            pass\n",
    "                        else:\n",
    "                            sigma += dA[output,  j-s] * self.W[output, chanel, s]\n",
    "                    dZ[chanel, j] += sigma        \n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 【問題8】学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
